{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HW3.ipynb","provenance":[],"collapsed_sections":[]},"coursera":{"course_slug":"neural-networks-deep-learning","graded_item_id":"XaIWT","launcher_item_id":"zAgPl"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"9OA0f9oxYGYb"},"source":["# HW#6 Regularization\n","\n","안녕하세요, 광운대학교 로봇학부의 오정현 교수입니다. 본 자료는 딥러닝 실습 수업을 위해 제작된 것입니다.\n","\n","파이썬 문법\n","- 점프투파이썬(https://wikidocs.net/book/1) 참고\n","\n","이번 과제는 딥러닝의 일반화 성능을 높이기 위한 Regularization을 해보는 것입니다.이미지 분류에 여러 가지 Regularization 기법을 적용해 보도록 하겠습니다. 대표적인 Regularization 기법으로 Dropout, Data augmentation, Batch Normalization 등이 있습니다.\n","\n","이번 과제는 (https://www.tensorflow.org/tutorials/keras/classification?hl=ko)를 참고하면 좋습니다."]},{"cell_type":"markdown","metadata":{"id":"L9KBzwzd7Bub"},"source":["#1. Data Generation\n","Data는 mnist dataset을 이용하도록 하겠습니다. mnist dataset은 원래 60000개의 training set이 주어져 있지만 overfitting을 유도하기 위하여 1000개의 data만 이용하려고 합니다. 1000개의 data로 이루어진 x_train과 y_train을 만들어 보세요. 그리고 2000개로 이루어진 large_x_train, large_y_train을 만들어보세요. 그리고 training data의 다른 범위에서 200개로 이루어진 x_validation과 y_validation도 만들어 보세요."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V3K3NqD_wTyh","executionInfo":{"status":"ok","timestamp":1619188718062,"user_tz":-540,"elapsed":3312,"user":{"displayName":"김태영","photoUrl":"","userId":"02983489978232498818"}},"outputId":"298da072-61b5-478f-e248-7955ad0263c8"},"source":["from __future__ import print_function\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, BatchNormalization, Activation, Flatten\n","from keras import backend as K\n","from matplotlib import pyplot\n","\n","batch_size = 28\n","num_classes = 10\n","epochs = 100\n","\n","# input image dimensions\n","img_rows, img_cols = 28, 28\n","\n","# the data, split between train and test sets\n","(X_train, Y_train), (x_test,y_test) = mnist.load_data()\n","\n","### START CODE HERE ###\n","x_validation = X_train[0:200,:,:]\n","y_validation = Y_train[0:200]\n","large_x_train = X_train[200:2200,:,:]\n","large_y_train = Y_train[200:2200]\n","x_train = X_train[2200:3200,:,:]\n","y_train = Y_train[2200:3200]\n","### END CODE HERE ###\n","print(\"x_validation shape:\", x_validation.shape)\n","print(\"y_validation shape:\", y_validation.shape)\n","if K.image_data_format() == 'channels_first':\n","    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n","    large_x_train = large_x_train.reshape(large_x_train.shape[0], 1, img_rows, img_cols)\n","    x_validation = x_validation.reshape(x_validation.shape[0], 1, img_rows, img_cols)\n","    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n","    input_shape = (1, img_rows, img_cols)\n","else:\n","    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n","    large_x_train = large_x_train.reshape(large_x_train.shape[0], img_rows, img_cols, 1)\n","    x_validation = x_validation.reshape(x_validation.shape[0], img_rows, img_cols, 1)\n","    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n","    input_shape = (img_rows, img_cols, 1)\n","\n","x_train = x_train.astype('float32')\n","large_x_train = large_x_train.astype('float32')\n","x_validation = x_validation.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","large_x_train /= 255\n","x_validation /= 255\n","x_test /= 255\n","\n","# convert class vectors to binary class matrices\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","large_y_train = keras.utils.to_categorical(large_y_train, num_classes)\n","y_validation = keras.utils.to_categorical(y_validation, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","assert large_x_train.shape[0]==2000\n","assert large_y_train.shape[0]==2000\n","assert x_train.shape[0]==1000\n","assert y_train.shape[0]==1000\n","assert x_validation.shape[0]==200\n","assert y_validation.shape[0]==200\n","\n","print(\"x_train shape:\", x_train.shape)\n","print(\"y_train shape:\", y_train.shape)\n","print(\"large_x_train shape:\", large_x_train.shape)\n","print(\"large_y_train shape:\", large_y_train.shape)\n","print(\"x_validation shape:\", x_validation.shape)\n","print(\"y_validation shape:\", y_validation.shape)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","x_validation shape: (200, 28, 28)\n","y_validation shape: (200,)\n","x_train shape: (1000, 28, 28, 1)\n","y_train shape: (1000, 10)\n","large_x_train shape: (2000, 28, 28, 1)\n","large_y_train shape: (2000, 10)\n","x_validation shape: (200, 28, 28, 1)\n","y_validation shape: (200, 10)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jlNTST2K_IRE"},"source":["#2. 모델 생성\n","복습 차원에서 MLP 분류모델을 만들어 보도록 하겠습니다. 모델의 마지막 레이어에는 활성화 함수로 10개의 출력을 가지는 softmax를 달겠습니다. 이를 통해서 모델은 이미지안의 숫자가 0부터 9까지의 숫자중에 어디에 가까운지를 확률적으로 나타냅니다. \n","\n"]},{"cell_type":"markdown","metadata":{"id":"TYNI8KWo8PyC"},"source":["다음과 같은 MLP 모델을 만들어 보세요.\n","\n","| Layer (type) | Output Shape | Param # |\n","|------|------|------|\n","| Flatten | (None, 784) | 0 |\n","| Dense | (None, 1024) | 803840 |\n","| Dense | (None, 1024) | 1049600 |\n","| Dense | (None, 1024) | 1049600 |\n","| Flatten | (None, 1024) | 0 |\n","| Dense | (None, 10) | 10250 |"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"560L-utPx8z1","executionInfo":{"status":"ok","timestamp":1619188723229,"user_tz":-540,"elapsed":8473,"user":{"displayName":"김태영","photoUrl":"","userId":"02983489978232498818"}},"outputId":"26e350aa-af75-432d-c6af-1d3937b1c736"},"source":["model = Sequential()\n","### START CODE HERE ###\n","model.add(Flatten(input_shape=(28,28)))\n","model.add(Dense(1024,activation='relu'))\n","model.add(Dense(1024,activation='relu'))\n","model.add(Dense(1024,activation='relu'))\n","model.add(Flatten(input_shape=(1024,)))\n","model.add(Dense(10,activation='softmax'))\n","### END CODE HERE ###\n","\n","model.summary()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","flatten (Flatten)            (None, 784)               0         \n","_________________________________________________________________\n","dense (Dense)                (None, 1024)              803840    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1024)              1049600   \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1024)              1049600   \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 10)                10250     \n","=================================================================\n","Total params: 2,913,290\n","Trainable params: 2,913,290\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"azhIfmZeBZm8"},"source":["#3. Learning MLP\n","기본 MLP 분류모델을 학습해 보겠습니다. Overfitting은 Training data에 맞추어 과도하게 학습이 이루어져 Test data에서 높은 성능이 나지 않는 현상, 즉 Generalization 성능이 높지 않게 나타나는 현상을 의미합니다. 따라서 Overfitting이 발생하면 Training accuracy는 높지만 Test accuracy는 높지 않게 나타납니다. \n","\n","현재 모델이 overfitting이 발생하는지 체크해 보세요. 일부러 overfitting이 발생하도록 유도하였기 때문에 overfitting 현상이 나타나야 합니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w1VoI2bCyBy-","executionInfo":{"status":"ok","timestamp":1619188745210,"user_tz":-540,"elapsed":30449,"user":{"displayName":"김태영","photoUrl":"","userId":"02983489978232498818"}},"outputId":"7e67ff72-126b-4acc-8aa9-8efbc998a12c"},"source":["model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=keras.optimizers.Adadelta(),\n","              metrics=['accuracy'])\n","weights = model.get_weights()\n","\n","history=model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_validation, y_validation))\n","\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","36/36 [==============================] - 3s 17ms/step - loss: 2.3050 - accuracy: 0.0918 - val_loss: 2.3047 - val_accuracy: 0.1100\n","Epoch 2/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.2932 - accuracy: 0.1119 - val_loss: 2.2956 - val_accuracy: 0.1200\n","Epoch 3/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.2859 - accuracy: 0.1182 - val_loss: 2.2866 - val_accuracy: 0.1750\n","Epoch 4/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.2703 - accuracy: 0.1514 - val_loss: 2.2776 - val_accuracy: 0.1900\n","Epoch 5/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.2627 - accuracy: 0.1759 - val_loss: 2.2687 - val_accuracy: 0.2000\n","Epoch 6/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.2564 - accuracy: 0.1953 - val_loss: 2.2598 - val_accuracy: 0.2200\n","Epoch 7/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.2457 - accuracy: 0.2269 - val_loss: 2.2510 - val_accuracy: 0.2500\n","Epoch 8/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.2323 - accuracy: 0.2867 - val_loss: 2.2422 - val_accuracy: 0.2650\n","Epoch 9/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.2188 - accuracy: 0.3249 - val_loss: 2.2334 - val_accuracy: 0.2950\n","Epoch 10/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.2158 - accuracy: 0.3205 - val_loss: 2.2247 - val_accuracy: 0.3200\n","Epoch 11/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.2102 - accuracy: 0.3376 - val_loss: 2.2159 - val_accuracy: 0.3500\n","Epoch 12/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.2006 - accuracy: 0.3950 - val_loss: 2.2072 - val_accuracy: 0.3800\n","Epoch 13/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.1846 - accuracy: 0.4337 - val_loss: 2.1984 - val_accuracy: 0.3900\n","Epoch 14/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.1810 - accuracy: 0.4338 - val_loss: 2.1896 - val_accuracy: 0.4050\n","Epoch 15/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.1701 - accuracy: 0.4749 - val_loss: 2.1809 - val_accuracy: 0.4450\n","Epoch 16/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.1594 - accuracy: 0.5133 - val_loss: 2.1721 - val_accuracy: 0.4700\n","Epoch 17/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.1505 - accuracy: 0.5059 - val_loss: 2.1633 - val_accuracy: 0.4900\n","Epoch 18/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.1354 - accuracy: 0.5658 - val_loss: 2.1544 - val_accuracy: 0.5100\n","Epoch 19/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.1296 - accuracy: 0.5709 - val_loss: 2.1455 - val_accuracy: 0.5100\n","Epoch 20/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.1214 - accuracy: 0.5758 - val_loss: 2.1365 - val_accuracy: 0.5300\n","Epoch 21/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.1156 - accuracy: 0.5737 - val_loss: 2.1275 - val_accuracy: 0.5350\n","Epoch 22/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.0976 - accuracy: 0.6008 - val_loss: 2.1185 - val_accuracy: 0.5450\n","Epoch 23/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.0916 - accuracy: 0.6036 - val_loss: 2.1094 - val_accuracy: 0.5550\n","Epoch 24/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.0860 - accuracy: 0.5986 - val_loss: 2.1003 - val_accuracy: 0.5600\n","Epoch 25/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.0768 - accuracy: 0.6306 - val_loss: 2.0911 - val_accuracy: 0.5650\n","Epoch 26/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.0595 - accuracy: 0.6407 - val_loss: 2.0818 - val_accuracy: 0.5650\n","Epoch 27/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.0552 - accuracy: 0.6510 - val_loss: 2.0725 - val_accuracy: 0.5700\n","Epoch 28/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.0451 - accuracy: 0.6415 - val_loss: 2.0630 - val_accuracy: 0.5750\n","Epoch 29/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.0323 - accuracy: 0.6727 - val_loss: 2.0535 - val_accuracy: 0.5750\n","Epoch 30/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.0148 - accuracy: 0.6847 - val_loss: 2.0438 - val_accuracy: 0.5800\n","Epoch 31/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.0143 - accuracy: 0.6902 - val_loss: 2.0340 - val_accuracy: 0.5900\n","Epoch 32/100\n","36/36 [==============================] - 0s 5ms/step - loss: 2.0040 - accuracy: 0.6889 - val_loss: 2.0243 - val_accuracy: 0.5900\n","Epoch 33/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.9892 - accuracy: 0.6757 - val_loss: 2.0144 - val_accuracy: 0.5900\n","Epoch 34/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.9894 - accuracy: 0.6864 - val_loss: 2.0046 - val_accuracy: 0.6000\n","Epoch 35/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.9688 - accuracy: 0.7050 - val_loss: 1.9947 - val_accuracy: 0.6000\n","Epoch 36/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.9661 - accuracy: 0.6850 - val_loss: 1.9847 - val_accuracy: 0.6100\n","Epoch 37/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.9460 - accuracy: 0.7109 - val_loss: 1.9747 - val_accuracy: 0.6100\n","Epoch 38/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.9380 - accuracy: 0.7222 - val_loss: 1.9646 - val_accuracy: 0.6150\n","Epoch 39/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.9150 - accuracy: 0.7188 - val_loss: 1.9544 - val_accuracy: 0.6200\n","Epoch 40/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.9062 - accuracy: 0.7330 - val_loss: 1.9442 - val_accuracy: 0.6200\n","Epoch 41/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.8999 - accuracy: 0.7128 - val_loss: 1.9339 - val_accuracy: 0.6250\n","Epoch 42/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.8907 - accuracy: 0.7171 - val_loss: 1.9235 - val_accuracy: 0.6300\n","Epoch 43/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.8801 - accuracy: 0.7418 - val_loss: 1.9130 - val_accuracy: 0.6300\n","Epoch 44/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.8729 - accuracy: 0.7399 - val_loss: 1.9025 - val_accuracy: 0.6400\n","Epoch 45/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.8548 - accuracy: 0.7393 - val_loss: 1.8918 - val_accuracy: 0.6450\n","Epoch 46/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.8337 - accuracy: 0.7409 - val_loss: 1.8810 - val_accuracy: 0.6500\n","Epoch 47/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.8426 - accuracy: 0.7499 - val_loss: 1.8702 - val_accuracy: 0.6500\n","Epoch 48/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.8168 - accuracy: 0.7502 - val_loss: 1.8593 - val_accuracy: 0.6500\n","Epoch 49/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.8142 - accuracy: 0.7422 - val_loss: 1.8484 - val_accuracy: 0.6550\n","Epoch 50/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.8030 - accuracy: 0.7400 - val_loss: 1.8374 - val_accuracy: 0.6500\n","Epoch 51/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.7921 - accuracy: 0.7488 - val_loss: 1.8262 - val_accuracy: 0.6550\n","Epoch 52/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.7791 - accuracy: 0.7566 - val_loss: 1.8151 - val_accuracy: 0.6500\n","Epoch 53/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.7592 - accuracy: 0.7597 - val_loss: 1.8039 - val_accuracy: 0.6600\n","Epoch 54/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.7717 - accuracy: 0.7374 - val_loss: 1.7925 - val_accuracy: 0.6600\n","Epoch 55/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.7410 - accuracy: 0.7606 - val_loss: 1.7812 - val_accuracy: 0.6600\n","Epoch 56/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.7348 - accuracy: 0.7462 - val_loss: 1.7698 - val_accuracy: 0.6600\n","Epoch 57/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.7245 - accuracy: 0.7530 - val_loss: 1.7583 - val_accuracy: 0.6650\n","Epoch 58/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.6925 - accuracy: 0.7805 - val_loss: 1.7468 - val_accuracy: 0.6650\n","Epoch 59/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.6940 - accuracy: 0.7572 - val_loss: 1.7354 - val_accuracy: 0.6650\n","Epoch 60/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.6789 - accuracy: 0.7670 - val_loss: 1.7238 - val_accuracy: 0.6650\n","Epoch 61/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.6799 - accuracy: 0.7744 - val_loss: 1.7122 - val_accuracy: 0.6700\n","Epoch 62/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.6762 - accuracy: 0.7410 - val_loss: 1.7005 - val_accuracy: 0.6750\n","Epoch 63/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.6419 - accuracy: 0.8028 - val_loss: 1.6888 - val_accuracy: 0.6750\n","Epoch 64/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.6089 - accuracy: 0.7933 - val_loss: 1.6771 - val_accuracy: 0.6800\n","Epoch 65/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.6168 - accuracy: 0.7770 - val_loss: 1.6654 - val_accuracy: 0.6750\n","Epoch 66/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.6106 - accuracy: 0.7700 - val_loss: 1.6534 - val_accuracy: 0.6750\n","Epoch 67/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.6165 - accuracy: 0.7580 - val_loss: 1.6415 - val_accuracy: 0.6750\n","Epoch 68/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.5760 - accuracy: 0.7990 - val_loss: 1.6296 - val_accuracy: 0.6750\n","Epoch 69/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.5598 - accuracy: 0.7851 - val_loss: 1.6177 - val_accuracy: 0.6750\n","Epoch 70/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.5492 - accuracy: 0.7989 - val_loss: 1.6057 - val_accuracy: 0.6750\n","Epoch 71/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.5328 - accuracy: 0.7747 - val_loss: 1.5936 - val_accuracy: 0.6750\n","Epoch 72/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.5408 - accuracy: 0.7871 - val_loss: 1.5816 - val_accuracy: 0.6750\n","Epoch 73/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.5131 - accuracy: 0.8008 - val_loss: 1.5696 - val_accuracy: 0.6750\n","Epoch 74/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.5151 - accuracy: 0.7769 - val_loss: 1.5575 - val_accuracy: 0.6750\n","Epoch 75/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.4722 - accuracy: 0.7929 - val_loss: 1.5456 - val_accuracy: 0.6750\n","Epoch 76/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.4887 - accuracy: 0.7907 - val_loss: 1.5336 - val_accuracy: 0.6750\n","Epoch 77/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.4486 - accuracy: 0.8160 - val_loss: 1.5217 - val_accuracy: 0.6800\n","Epoch 78/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.4548 - accuracy: 0.7989 - val_loss: 1.5097 - val_accuracy: 0.6900\n","Epoch 79/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.4452 - accuracy: 0.7794 - val_loss: 1.4979 - val_accuracy: 0.6900\n","Epoch 80/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.4156 - accuracy: 0.8179 - val_loss: 1.4860 - val_accuracy: 0.6950\n","Epoch 81/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.4190 - accuracy: 0.7990 - val_loss: 1.4742 - val_accuracy: 0.6900\n","Epoch 82/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.4003 - accuracy: 0.7980 - val_loss: 1.4624 - val_accuracy: 0.6900\n","Epoch 83/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.3885 - accuracy: 0.8029 - val_loss: 1.4506 - val_accuracy: 0.6900\n","Epoch 84/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.3927 - accuracy: 0.7682 - val_loss: 1.4391 - val_accuracy: 0.6850\n","Epoch 85/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.3834 - accuracy: 0.7920 - val_loss: 1.4274 - val_accuracy: 0.6850\n","Epoch 86/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.3250 - accuracy: 0.8037 - val_loss: 1.4159 - val_accuracy: 0.6850\n","Epoch 87/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.3363 - accuracy: 0.8110 - val_loss: 1.4044 - val_accuracy: 0.6850\n","Epoch 88/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.3396 - accuracy: 0.8096 - val_loss: 1.3930 - val_accuracy: 0.6900\n","Epoch 89/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.3133 - accuracy: 0.8006 - val_loss: 1.3815 - val_accuracy: 0.7000\n","Epoch 90/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.3251 - accuracy: 0.7910 - val_loss: 1.3702 - val_accuracy: 0.7000\n","Epoch 91/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.2747 - accuracy: 0.8043 - val_loss: 1.3590 - val_accuracy: 0.7000\n","Epoch 92/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.2534 - accuracy: 0.8154 - val_loss: 1.3480 - val_accuracy: 0.7000\n","Epoch 93/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.2358 - accuracy: 0.8205 - val_loss: 1.3370 - val_accuracy: 0.7100\n","Epoch 94/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.2572 - accuracy: 0.8188 - val_loss: 1.3259 - val_accuracy: 0.7100\n","Epoch 95/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.2439 - accuracy: 0.8131 - val_loss: 1.3150 - val_accuracy: 0.7200\n","Epoch 96/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.2305 - accuracy: 0.8118 - val_loss: 1.3042 - val_accuracy: 0.7200\n","Epoch 97/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.2188 - accuracy: 0.8226 - val_loss: 1.2934 - val_accuracy: 0.7250\n","Epoch 98/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.2068 - accuracy: 0.8271 - val_loss: 1.2827 - val_accuracy: 0.7250\n","Epoch 99/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.2065 - accuracy: 0.8009 - val_loss: 1.2723 - val_accuracy: 0.7250\n","Epoch 100/100\n","36/36 [==============================] - 0s 5ms/step - loss: 1.1901 - accuracy: 0.8205 - val_loss: 1.2618 - val_accuracy: 0.7250\n","Test loss: 1.2676689624786377\n","Test accuracy: 0.7620999813079834\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1jebNKzFBJGE"},"source":["#4. Regularization\n","Overfitting이 발생한 모델에 다양한 Regularization 기법을 이용해 보도록 합시다."]},{"cell_type":"markdown","metadata":{"id":"WsxZKsjCFvhT"},"source":["4.1 Large Dataset\n","\n","Training data가 충분하다면 overfitting 현상이 발생할 가능성이 줄어듭니다. 기본 MLP 분류 모델에서 large_x_train과 large_y_train을 이용하면 성능이 올라갈 것입니다. Generalization 성능이 올라갔나요?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O5b1fp96FuEy","executionInfo":{"status":"ok","timestamp":1619188777190,"user_tz":-540,"elapsed":62426,"user":{"displayName":"김태영","photoUrl":"","userId":"02983489978232498818"}},"outputId":"68d227d6-4682-47d9-a702-d9f44ed6d243"},"source":["#initialize weights\n","model.set_weights(weights)\n","\n","large_model_history=model.fit(large_x_train, large_y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_validation, y_validation))\n","\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Largemodel Test loss:', score[0])\n","print('Largemodel Test accuracy:', score[1])"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","72/72 [==============================] - 0s 5ms/step - loss: 2.2926 - accuracy: 0.1240 - val_loss: 2.2956 - val_accuracy: 0.1500\n","Epoch 2/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.2740 - accuracy: 0.1660 - val_loss: 2.2777 - val_accuracy: 0.1850\n","Epoch 3/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.2556 - accuracy: 0.2130 - val_loss: 2.2599 - val_accuracy: 0.2500\n","Epoch 4/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.2375 - accuracy: 0.2665 - val_loss: 2.2423 - val_accuracy: 0.2950\n","Epoch 5/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.2195 - accuracy: 0.3355 - val_loss: 2.2249 - val_accuracy: 0.3600\n","Epoch 6/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.2015 - accuracy: 0.3820 - val_loss: 2.2074 - val_accuracy: 0.3850\n","Epoch 7/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.1835 - accuracy: 0.4420 - val_loss: 2.1899 - val_accuracy: 0.4300\n","Epoch 8/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.1655 - accuracy: 0.4890 - val_loss: 2.1723 - val_accuracy: 0.4850\n","Epoch 9/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.1474 - accuracy: 0.5270 - val_loss: 2.1547 - val_accuracy: 0.5250\n","Epoch 10/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.1292 - accuracy: 0.5560 - val_loss: 2.1371 - val_accuracy: 0.5500\n","Epoch 11/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.1109 - accuracy: 0.5795 - val_loss: 2.1192 - val_accuracy: 0.5650\n","Epoch 12/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.0924 - accuracy: 0.5920 - val_loss: 2.1013 - val_accuracy: 0.5800\n","Epoch 13/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.0738 - accuracy: 0.6120 - val_loss: 2.0832 - val_accuracy: 0.6000\n","Epoch 14/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.0550 - accuracy: 0.6315 - val_loss: 2.0648 - val_accuracy: 0.6250\n","Epoch 15/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.0358 - accuracy: 0.6475 - val_loss: 2.0461 - val_accuracy: 0.6400\n","Epoch 16/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.0166 - accuracy: 0.6660 - val_loss: 2.0273 - val_accuracy: 0.6450\n","Epoch 17/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.9971 - accuracy: 0.6750 - val_loss: 2.0082 - val_accuracy: 0.6600\n","Epoch 18/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.9774 - accuracy: 0.6775 - val_loss: 1.9889 - val_accuracy: 0.6700\n","Epoch 19/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.9574 - accuracy: 0.6895 - val_loss: 1.9694 - val_accuracy: 0.6700\n","Epoch 20/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.9373 - accuracy: 0.6940 - val_loss: 1.9497 - val_accuracy: 0.6700\n","Epoch 21/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.9168 - accuracy: 0.7030 - val_loss: 1.9297 - val_accuracy: 0.6750\n","Epoch 22/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.8961 - accuracy: 0.7065 - val_loss: 1.9093 - val_accuracy: 0.6750\n","Epoch 23/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.8750 - accuracy: 0.7130 - val_loss: 1.8886 - val_accuracy: 0.6800\n","Epoch 24/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.8535 - accuracy: 0.7180 - val_loss: 1.8677 - val_accuracy: 0.6800\n","Epoch 25/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.8318 - accuracy: 0.7255 - val_loss: 1.8465 - val_accuracy: 0.6800\n","Epoch 26/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.8098 - accuracy: 0.7305 - val_loss: 1.8252 - val_accuracy: 0.6900\n","Epoch 27/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.7876 - accuracy: 0.7315 - val_loss: 1.8035 - val_accuracy: 0.6900\n","Epoch 28/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.7650 - accuracy: 0.7395 - val_loss: 1.7815 - val_accuracy: 0.6900\n","Epoch 29/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.7422 - accuracy: 0.7425 - val_loss: 1.7592 - val_accuracy: 0.7050\n","Epoch 30/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.7191 - accuracy: 0.7490 - val_loss: 1.7367 - val_accuracy: 0.7050\n","Epoch 31/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.6958 - accuracy: 0.7535 - val_loss: 1.7142 - val_accuracy: 0.7100\n","Epoch 32/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.6723 - accuracy: 0.7620 - val_loss: 1.6914 - val_accuracy: 0.7150\n","Epoch 33/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.6486 - accuracy: 0.7645 - val_loss: 1.6684 - val_accuracy: 0.7150\n","Epoch 34/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.6247 - accuracy: 0.7690 - val_loss: 1.6452 - val_accuracy: 0.7250\n","Epoch 35/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.6007 - accuracy: 0.7680 - val_loss: 1.6221 - val_accuracy: 0.7350\n","Epoch 36/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.5767 - accuracy: 0.7720 - val_loss: 1.5990 - val_accuracy: 0.7250\n","Epoch 37/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.5527 - accuracy: 0.7760 - val_loss: 1.5758 - val_accuracy: 0.7250\n","Epoch 38/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.5285 - accuracy: 0.7780 - val_loss: 1.5523 - val_accuracy: 0.7300\n","Epoch 39/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.5043 - accuracy: 0.7790 - val_loss: 1.5290 - val_accuracy: 0.7250\n","Epoch 40/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.4800 - accuracy: 0.7840 - val_loss: 1.5055 - val_accuracy: 0.7350\n","Epoch 41/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.4558 - accuracy: 0.7860 - val_loss: 1.4825 - val_accuracy: 0.7250\n","Epoch 42/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.4316 - accuracy: 0.7880 - val_loss: 1.4593 - val_accuracy: 0.7300\n","Epoch 43/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.4076 - accuracy: 0.7925 - val_loss: 1.4365 - val_accuracy: 0.7350\n","Epoch 44/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.3837 - accuracy: 0.7985 - val_loss: 1.4138 - val_accuracy: 0.7350\n","Epoch 45/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.3601 - accuracy: 0.7975 - val_loss: 1.3914 - val_accuracy: 0.7350\n","Epoch 46/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.3368 - accuracy: 0.8025 - val_loss: 1.3692 - val_accuracy: 0.7350\n","Epoch 47/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.3137 - accuracy: 0.8050 - val_loss: 1.3471 - val_accuracy: 0.7450\n","Epoch 48/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.2910 - accuracy: 0.8065 - val_loss: 1.3252 - val_accuracy: 0.7450\n","Epoch 49/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.2686 - accuracy: 0.8075 - val_loss: 1.3041 - val_accuracy: 0.7500\n","Epoch 50/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.2467 - accuracy: 0.8105 - val_loss: 1.2830 - val_accuracy: 0.7500\n","Epoch 51/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.2251 - accuracy: 0.8130 - val_loss: 1.2624 - val_accuracy: 0.7550\n","Epoch 52/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.2038 - accuracy: 0.8145 - val_loss: 1.2425 - val_accuracy: 0.7700\n","Epoch 53/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.1830 - accuracy: 0.8135 - val_loss: 1.2227 - val_accuracy: 0.7750\n","Epoch 54/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.1625 - accuracy: 0.8190 - val_loss: 1.2029 - val_accuracy: 0.7800\n","Epoch 55/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.1424 - accuracy: 0.8225 - val_loss: 1.1840 - val_accuracy: 0.7800\n","Epoch 56/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.1227 - accuracy: 0.8230 - val_loss: 1.1653 - val_accuracy: 0.7800\n","Epoch 57/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.1032 - accuracy: 0.8260 - val_loss: 1.1466 - val_accuracy: 0.7850\n","Epoch 58/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.0843 - accuracy: 0.8290 - val_loss: 1.1285 - val_accuracy: 0.7900\n","Epoch 59/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.0658 - accuracy: 0.8315 - val_loss: 1.1112 - val_accuracy: 0.7950\n","Epoch 60/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.0477 - accuracy: 0.8335 - val_loss: 1.0937 - val_accuracy: 0.7950\n","Epoch 61/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.0301 - accuracy: 0.8375 - val_loss: 1.0772 - val_accuracy: 0.7950\n","Epoch 62/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.0130 - accuracy: 0.8380 - val_loss: 1.0605 - val_accuracy: 0.8000\n","Epoch 63/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.9963 - accuracy: 0.8380 - val_loss: 1.0448 - val_accuracy: 0.8000\n","Epoch 64/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.9800 - accuracy: 0.8415 - val_loss: 1.0293 - val_accuracy: 0.8000\n","Epoch 65/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.9643 - accuracy: 0.8440 - val_loss: 1.0147 - val_accuracy: 0.8000\n","Epoch 66/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.9488 - accuracy: 0.8455 - val_loss: 1.0001 - val_accuracy: 0.8000\n","Epoch 67/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.9338 - accuracy: 0.8460 - val_loss: 0.9863 - val_accuracy: 0.8000\n","Epoch 68/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.9191 - accuracy: 0.8485 - val_loss: 0.9726 - val_accuracy: 0.8000\n","Epoch 69/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.9048 - accuracy: 0.8490 - val_loss: 0.9587 - val_accuracy: 0.8000\n","Epoch 70/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.8908 - accuracy: 0.8500 - val_loss: 0.9461 - val_accuracy: 0.8000\n","Epoch 71/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.8773 - accuracy: 0.8525 - val_loss: 0.9334 - val_accuracy: 0.8000\n","Epoch 72/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.8641 - accuracy: 0.8535 - val_loss: 0.9209 - val_accuracy: 0.8000\n","Epoch 73/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.8513 - accuracy: 0.8535 - val_loss: 0.9090 - val_accuracy: 0.8050\n","Epoch 74/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.8390 - accuracy: 0.8545 - val_loss: 0.8971 - val_accuracy: 0.8000\n","Epoch 75/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.8269 - accuracy: 0.8545 - val_loss: 0.8860 - val_accuracy: 0.8000\n","Epoch 76/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.8152 - accuracy: 0.8550 - val_loss: 0.8752 - val_accuracy: 0.8000\n","Epoch 77/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.8039 - accuracy: 0.8570 - val_loss: 0.8649 - val_accuracy: 0.8000\n","Epoch 78/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.7929 - accuracy: 0.8595 - val_loss: 0.8545 - val_accuracy: 0.8000\n","Epoch 79/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.7821 - accuracy: 0.8605 - val_loss: 0.8445 - val_accuracy: 0.8050\n","Epoch 80/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.7716 - accuracy: 0.8610 - val_loss: 0.8350 - val_accuracy: 0.8100\n","Epoch 81/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.7615 - accuracy: 0.8615 - val_loss: 0.8257 - val_accuracy: 0.8150\n","Epoch 82/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.7516 - accuracy: 0.8615 - val_loss: 0.8166 - val_accuracy: 0.8150\n","Epoch 83/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.7419 - accuracy: 0.8615 - val_loss: 0.8078 - val_accuracy: 0.8150\n","Epoch 84/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.7326 - accuracy: 0.8620 - val_loss: 0.7988 - val_accuracy: 0.8150\n","Epoch 85/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.7235 - accuracy: 0.8615 - val_loss: 0.7904 - val_accuracy: 0.8150\n","Epoch 86/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.7147 - accuracy: 0.8645 - val_loss: 0.7821 - val_accuracy: 0.8150\n","Epoch 87/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.7061 - accuracy: 0.8650 - val_loss: 0.7741 - val_accuracy: 0.8200\n","Epoch 88/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.6978 - accuracy: 0.8655 - val_loss: 0.7664 - val_accuracy: 0.8200\n","Epoch 89/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.6897 - accuracy: 0.8660 - val_loss: 0.7585 - val_accuracy: 0.8200\n","Epoch 90/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.6818 - accuracy: 0.8685 - val_loss: 0.7516 - val_accuracy: 0.8300\n","Epoch 91/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.6742 - accuracy: 0.8670 - val_loss: 0.7449 - val_accuracy: 0.8250\n","Epoch 92/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.6666 - accuracy: 0.8680 - val_loss: 0.7375 - val_accuracy: 0.8350\n","Epoch 93/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.6594 - accuracy: 0.8710 - val_loss: 0.7312 - val_accuracy: 0.8350\n","Epoch 94/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.6523 - accuracy: 0.8700 - val_loss: 0.7248 - val_accuracy: 0.8350\n","Epoch 95/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.6454 - accuracy: 0.8720 - val_loss: 0.7183 - val_accuracy: 0.8350\n","Epoch 96/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.6387 - accuracy: 0.8725 - val_loss: 0.7121 - val_accuracy: 0.8350\n","Epoch 97/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.6321 - accuracy: 0.8730 - val_loss: 0.7064 - val_accuracy: 0.8300\n","Epoch 98/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.6257 - accuracy: 0.8735 - val_loss: 0.7004 - val_accuracy: 0.8350\n","Epoch 99/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.6195 - accuracy: 0.8750 - val_loss: 0.6948 - val_accuracy: 0.8350\n","Epoch 100/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.6133 - accuracy: 0.8740 - val_loss: 0.6890 - val_accuracy: 0.8350\n","Largemodel Test loss: 0.6781101822853088\n","Largemodel Test accuracy: 0.8417999744415283\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6j_-85YFDA6y"},"source":["##4.2 Dropout\n","Dropout은 쉽게 쓸 수 있는 Regularization 기법입니다. Layer 사이에 Dropout layer만 추가하면 되기 때문에 간편합니다. 다음과 같은 Dropout model을 만들어 보세요.\n","\n","| Layer (type) | Output Shape | Param # |\n","|------|------|------|\n","| Flatten | (None, 784) | 0 |\n","| Dense | (None, 1024) | 803840 |\n","| Dense | (None, 1024) | 1049600 |\n","| Dense | (None, 1024) | 1049600 |\n","| Dropout | (None, 1024) | 0 |\n","| Flatten | (None, 1024) | 0 |\n","| Dense | (None, 10) | 10250 |"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DvYHpRcVDX22","executionInfo":{"status":"ok","timestamp":1619188777190,"user_tz":-540,"elapsed":62423,"user":{"displayName":"김태영","photoUrl":"","userId":"02983489978232498818"}},"outputId":"acc858d9-4b25-4fa2-cf10-0a6384e51778"},"source":["dropout_model = Sequential()\n","### START CODE HERE ###\n","dropout_model.add(Flatten(input_shape=(28,28)))\n","dropout_model.add(Dense(1024,activation='relu'))\n","dropout_model.add(Dense(1024,activation='relu'))\n","dropout_model.add(Dense(1024,activation='relu'))\n","dropout_model.add(Dropout(0.3))\n","dropout_model.add(Flatten(input_shape=(1024,)))\n","dropout_model.add(Dense(10,activation='softmax'))\n","### END CODE HERE ###\n","\n","dropout_model.summary()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","flatten_2 (Flatten)          (None, 784)               0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1024)              803840    \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 1024)              1049600   \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 1024)              1049600   \n","_________________________________________________________________\n","dropout (Dropout)            (None, 1024)              0         \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 10)                10250     \n","=================================================================\n","Total params: 2,913,290\n","Trainable params: 2,913,290\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"iSuxjOGWEKo9"},"source":["Dropout Model을 학습해 보겠습니다. Generalization 성능이 올라갔나요?\n","\n","※Dropout을 적용한 Model은 일정확률로 신경망의 뉴런을 비활성화시키기 때문에, 오버피팅을 방지하는 효과가 있습니다. 하지만 비활성화로 인해서  학습속도가 떨어진다는 단점이 존재합니다. 그 때문에 test accuracy는 같은 학습파라미터 조건에서 기존모델보다 더 낮을 수 있습니다. \n","\n","기존모델과 dropout을 적용한 모델에 대해서, train 데이터와 test데이터에 대한 accuracy차이를 주목해보시면 좋을 것같습니다!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fqMK-jsyED_h","executionInfo":{"status":"ok","timestamp":1619188808509,"user_tz":-540,"elapsed":93739,"user":{"displayName":"김태영","photoUrl":"","userId":"02983489978232498818"}},"outputId":"80a85422-a83f-4904-e316-f48ca8a9d817"},"source":["dropout_model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=keras.optimizers.Adadelta(),\n","              metrics=['accuracy'])\n","\n","dropout_model_history=dropout_model.fit(large_x_train, large_y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_validation, y_validation))\n","\n","score = dropout_model.evaluate(x_test, y_test, verbose=0)\n","print('Dropout model Test loss:', score[0])\n","print('Dropout model Test accuracy:', score[1])"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","72/72 [==============================] - 1s 6ms/step - loss: 2.3230 - accuracy: 0.1107 - val_loss: 2.3167 - val_accuracy: 0.1200\n","Epoch 2/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.3042 - accuracy: 0.1157 - val_loss: 2.2957 - val_accuracy: 0.1200\n","Epoch 3/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.2787 - accuracy: 0.1254 - val_loss: 2.2756 - val_accuracy: 0.1200\n","Epoch 4/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.2701 - accuracy: 0.1281 - val_loss: 2.2559 - val_accuracy: 0.1250\n","Epoch 5/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.2487 - accuracy: 0.1261 - val_loss: 2.2365 - val_accuracy: 0.1650\n","Epoch 6/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.2258 - accuracy: 0.1771 - val_loss: 2.2176 - val_accuracy: 0.2100\n","Epoch 7/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.2123 - accuracy: 0.2036 - val_loss: 2.1990 - val_accuracy: 0.2750\n","Epoch 8/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.1865 - accuracy: 0.2501 - val_loss: 2.1804 - val_accuracy: 0.3400\n","Epoch 9/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.1671 - accuracy: 0.3015 - val_loss: 2.1617 - val_accuracy: 0.4050\n","Epoch 10/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.1468 - accuracy: 0.3599 - val_loss: 2.1428 - val_accuracy: 0.4550\n","Epoch 11/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.1313 - accuracy: 0.4002 - val_loss: 2.1242 - val_accuracy: 0.4900\n","Epoch 12/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.1111 - accuracy: 0.4426 - val_loss: 2.1056 - val_accuracy: 0.5650\n","Epoch 13/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.0897 - accuracy: 0.4736 - val_loss: 2.0870 - val_accuracy: 0.6050\n","Epoch 14/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.0675 - accuracy: 0.5174 - val_loss: 2.0683 - val_accuracy: 0.6400\n","Epoch 15/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.0535 - accuracy: 0.5262 - val_loss: 2.0492 - val_accuracy: 0.6550\n","Epoch 16/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.0399 - accuracy: 0.5488 - val_loss: 2.0301 - val_accuracy: 0.6650\n","Epoch 17/100\n","72/72 [==============================] - 0s 4ms/step - loss: 2.0149 - accuracy: 0.5724 - val_loss: 2.0107 - val_accuracy: 0.6700\n","Epoch 18/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.9949 - accuracy: 0.5948 - val_loss: 1.9914 - val_accuracy: 0.6750\n","Epoch 19/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.9759 - accuracy: 0.6043 - val_loss: 1.9718 - val_accuracy: 0.6950\n","Epoch 20/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.9562 - accuracy: 0.6305 - val_loss: 1.9521 - val_accuracy: 0.7150\n","Epoch 21/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.9282 - accuracy: 0.6459 - val_loss: 1.9325 - val_accuracy: 0.7150\n","Epoch 22/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.9168 - accuracy: 0.6573 - val_loss: 1.9125 - val_accuracy: 0.7250\n","Epoch 23/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.8965 - accuracy: 0.6750 - val_loss: 1.8923 - val_accuracy: 0.7250\n","Epoch 24/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.8794 - accuracy: 0.6749 - val_loss: 1.8719 - val_accuracy: 0.7300\n","Epoch 25/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.8555 - accuracy: 0.6653 - val_loss: 1.8513 - val_accuracy: 0.7350\n","Epoch 26/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.8406 - accuracy: 0.6906 - val_loss: 1.8304 - val_accuracy: 0.7400\n","Epoch 27/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.8183 - accuracy: 0.6917 - val_loss: 1.8094 - val_accuracy: 0.7450\n","Epoch 28/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.7840 - accuracy: 0.7247 - val_loss: 1.7883 - val_accuracy: 0.7450\n","Epoch 29/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.7778 - accuracy: 0.7149 - val_loss: 1.7669 - val_accuracy: 0.7400\n","Epoch 30/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.7486 - accuracy: 0.7062 - val_loss: 1.7455 - val_accuracy: 0.7450\n","Epoch 31/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.7341 - accuracy: 0.6997 - val_loss: 1.7238 - val_accuracy: 0.7500\n","Epoch 32/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.7119 - accuracy: 0.7378 - val_loss: 1.7020 - val_accuracy: 0.7650\n","Epoch 33/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.6815 - accuracy: 0.7306 - val_loss: 1.6803 - val_accuracy: 0.7650\n","Epoch 34/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.6575 - accuracy: 0.7317 - val_loss: 1.6584 - val_accuracy: 0.7650\n","Epoch 35/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.6505 - accuracy: 0.7234 - val_loss: 1.6364 - val_accuracy: 0.7650\n","Epoch 36/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.6296 - accuracy: 0.7354 - val_loss: 1.6147 - val_accuracy: 0.7650\n","Epoch 37/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.6014 - accuracy: 0.7385 - val_loss: 1.5926 - val_accuracy: 0.7650\n","Epoch 38/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.5848 - accuracy: 0.7524 - val_loss: 1.5710 - val_accuracy: 0.7650\n","Epoch 39/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.5447 - accuracy: 0.7526 - val_loss: 1.5490 - val_accuracy: 0.7700\n","Epoch 40/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.5148 - accuracy: 0.7815 - val_loss: 1.5271 - val_accuracy: 0.7700\n","Epoch 41/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.5082 - accuracy: 0.7729 - val_loss: 1.5051 - val_accuracy: 0.7700\n","Epoch 42/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.4680 - accuracy: 0.7772 - val_loss: 1.4835 - val_accuracy: 0.7750\n","Epoch 43/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.4452 - accuracy: 0.7830 - val_loss: 1.4624 - val_accuracy: 0.7850\n","Epoch 44/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.4325 - accuracy: 0.7780 - val_loss: 1.4409 - val_accuracy: 0.7900\n","Epoch 45/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.4267 - accuracy: 0.7729 - val_loss: 1.4198 - val_accuracy: 0.7950\n","Epoch 46/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.4081 - accuracy: 0.7831 - val_loss: 1.3989 - val_accuracy: 0.7950\n","Epoch 47/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.3680 - accuracy: 0.7775 - val_loss: 1.3784 - val_accuracy: 0.7950\n","Epoch 48/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.3524 - accuracy: 0.7933 - val_loss: 1.3581 - val_accuracy: 0.8000\n","Epoch 49/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.3219 - accuracy: 0.7872 - val_loss: 1.3381 - val_accuracy: 0.8000\n","Epoch 50/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.3107 - accuracy: 0.7925 - val_loss: 1.3182 - val_accuracy: 0.8000\n","Epoch 51/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.3079 - accuracy: 0.7675 - val_loss: 1.2986 - val_accuracy: 0.8050\n","Epoch 52/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.2612 - accuracy: 0.7939 - val_loss: 1.2793 - val_accuracy: 0.8150\n","Epoch 53/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.2393 - accuracy: 0.7940 - val_loss: 1.2599 - val_accuracy: 0.8150\n","Epoch 54/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.2305 - accuracy: 0.7951 - val_loss: 1.2410 - val_accuracy: 0.8150\n","Epoch 55/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.2022 - accuracy: 0.7983 - val_loss: 1.2227 - val_accuracy: 0.8150\n","Epoch 56/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.1963 - accuracy: 0.8077 - val_loss: 1.2048 - val_accuracy: 0.8150\n","Epoch 57/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.1591 - accuracy: 0.8191 - val_loss: 1.1870 - val_accuracy: 0.8150\n","Epoch 58/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.1393 - accuracy: 0.8153 - val_loss: 1.1700 - val_accuracy: 0.8150\n","Epoch 59/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.1420 - accuracy: 0.7954 - val_loss: 1.1532 - val_accuracy: 0.8200\n","Epoch 60/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.1120 - accuracy: 0.8119 - val_loss: 1.1371 - val_accuracy: 0.8200\n","Epoch 61/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.1177 - accuracy: 0.8037 - val_loss: 1.1208 - val_accuracy: 0.8200\n","Epoch 62/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.0814 - accuracy: 0.8127 - val_loss: 1.1052 - val_accuracy: 0.8200\n","Epoch 63/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.0628 - accuracy: 0.8196 - val_loss: 1.0896 - val_accuracy: 0.8200\n","Epoch 64/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.0344 - accuracy: 0.8254 - val_loss: 1.0744 - val_accuracy: 0.8250\n","Epoch 65/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.0616 - accuracy: 0.7954 - val_loss: 1.0597 - val_accuracy: 0.8250\n","Epoch 66/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.0339 - accuracy: 0.8216 - val_loss: 1.0453 - val_accuracy: 0.8250\n","Epoch 67/100\n","72/72 [==============================] - 0s 4ms/step - loss: 1.0038 - accuracy: 0.8178 - val_loss: 1.0312 - val_accuracy: 0.8250\n","Epoch 68/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.9776 - accuracy: 0.8235 - val_loss: 1.0178 - val_accuracy: 0.8250\n","Epoch 69/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.9823 - accuracy: 0.8217 - val_loss: 1.0043 - val_accuracy: 0.8300\n","Epoch 70/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.9546 - accuracy: 0.8267 - val_loss: 0.9917 - val_accuracy: 0.8350\n","Epoch 71/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.9484 - accuracy: 0.8142 - val_loss: 0.9789 - val_accuracy: 0.8400\n","Epoch 72/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.9326 - accuracy: 0.8290 - val_loss: 0.9665 - val_accuracy: 0.8400\n","Epoch 73/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.9336 - accuracy: 0.8355 - val_loss: 0.9546 - val_accuracy: 0.8400\n","Epoch 74/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.9115 - accuracy: 0.8330 - val_loss: 0.9428 - val_accuracy: 0.8400\n","Epoch 75/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.9110 - accuracy: 0.8335 - val_loss: 0.9309 - val_accuracy: 0.8450\n","Epoch 76/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.8964 - accuracy: 0.8389 - val_loss: 0.9195 - val_accuracy: 0.8450\n","Epoch 77/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.9219 - accuracy: 0.8254 - val_loss: 0.9088 - val_accuracy: 0.8450\n","Epoch 78/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.8782 - accuracy: 0.8320 - val_loss: 0.8982 - val_accuracy: 0.8450\n","Epoch 79/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.8661 - accuracy: 0.8399 - val_loss: 0.8879 - val_accuracy: 0.8450\n","Epoch 80/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.8535 - accuracy: 0.8349 - val_loss: 0.8780 - val_accuracy: 0.8450\n","Epoch 81/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.8122 - accuracy: 0.8500 - val_loss: 0.8685 - val_accuracy: 0.8450\n","Epoch 82/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.8257 - accuracy: 0.8439 - val_loss: 0.8594 - val_accuracy: 0.8450\n","Epoch 83/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.8124 - accuracy: 0.8375 - val_loss: 0.8501 - val_accuracy: 0.8450\n","Epoch 84/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.8069 - accuracy: 0.8480 - val_loss: 0.8411 - val_accuracy: 0.8500\n","Epoch 85/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.8026 - accuracy: 0.8449 - val_loss: 0.8326 - val_accuracy: 0.8500\n","Epoch 86/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.7932 - accuracy: 0.8383 - val_loss: 0.8238 - val_accuracy: 0.8550\n","Epoch 87/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.7741 - accuracy: 0.8423 - val_loss: 0.8156 - val_accuracy: 0.8550\n","Epoch 88/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.8036 - accuracy: 0.8370 - val_loss: 0.8077 - val_accuracy: 0.8550\n","Epoch 89/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.7679 - accuracy: 0.8540 - val_loss: 0.7996 - val_accuracy: 0.8550\n","Epoch 90/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.7622 - accuracy: 0.8351 - val_loss: 0.7919 - val_accuracy: 0.8550\n","Epoch 91/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.7252 - accuracy: 0.8545 - val_loss: 0.7849 - val_accuracy: 0.8600\n","Epoch 92/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.7350 - accuracy: 0.8493 - val_loss: 0.7777 - val_accuracy: 0.8600\n","Epoch 93/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.7597 - accuracy: 0.8466 - val_loss: 0.7710 - val_accuracy: 0.8600\n","Epoch 94/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.7065 - accuracy: 0.8625 - val_loss: 0.7636 - val_accuracy: 0.8700\n","Epoch 95/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.7408 - accuracy: 0.8502 - val_loss: 0.7566 - val_accuracy: 0.8700\n","Epoch 96/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.7041 - accuracy: 0.8502 - val_loss: 0.7500 - val_accuracy: 0.8700\n","Epoch 97/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.7115 - accuracy: 0.8516 - val_loss: 0.7433 - val_accuracy: 0.8700\n","Epoch 98/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.6913 - accuracy: 0.8507 - val_loss: 0.7372 - val_accuracy: 0.8700\n","Epoch 99/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.6923 - accuracy: 0.8557 - val_loss: 0.7315 - val_accuracy: 0.8700\n","Epoch 100/100\n","72/72 [==============================] - 0s 4ms/step - loss: 0.6940 - accuracy: 0.8559 - val_loss: 0.7254 - val_accuracy: 0.8700\n","Dropout model Test loss: 0.7183159589767456\n","Dropout model Test accuracy: 0.8406000137329102\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AEyhMagnGq8F"},"source":["##4.3 BatchNormalization\n","BatchNormalization(BN)은 쉽게 쓸 수 있는 Regularization 기법입니다. Layer 사이에 BN layer만 추가하면 되기 때문에 간편합니다. 다음과 같은 BN model을 만들어 보세요.\n","\n","| Layer (type) | Output Shape | Param # |\n","|------|------|------|\n","| Flatten | (None, 784) | 0 |\n","| Dense | (None, 1024) | 803840 |\n","| BatchNormalization | (None, 1024) | 4096 |\n","| Activation | (None, 1024) | 0 |\n","| Dense | (None, 1024) | 1049600 |\n","| BatchNormalization | (None, 1024) | 4096 |\n","| Activation | (None, 1024) | 0 |\n","| Dense | (None, 1024) | 1049600 |\n","| BatchNormalization | (None, 1024) | 4096 |\n","| Activation | (None, 1024) | 0 |\n","| Flatten | (None, 1024) | 0 |\n","| Dense | (None, 10) | 10250 |"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sOIBMssiBJaB","executionInfo":{"status":"ok","timestamp":1619188808774,"user_tz":-540,"elapsed":94002,"user":{"displayName":"김태영","photoUrl":"","userId":"02983489978232498818"}},"outputId":"1e58dda0-bd5b-4a54-af01-9052992319be"},"source":["bn_model = Sequential()\n","### START CODE HERE ###\n","bn_model.add(Flatten(input_shape=(28,28)))\n","bn_model.add(Dense(1024))\n","bn_model.add(BatchNormalization())\n","bn_model.add(Activation('relu'))\n","bn_model.add(Dense(1024))\n","bn_model.add(BatchNormalization())\n","bn_model.add(Activation('relu'))\n","bn_model.add(Dense(1024))\n","bn_model.add(BatchNormalization())\n","bn_model.add(Activation('relu'))\n","bn_model.add(Flatten(input_shape=(1024,)))\n","bn_model.add(Dense(10,activation='softmax'))\n","### END CODE HERE ###\n","bn_model.summary()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","flatten_4 (Flatten)          (None, 784)               0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 1024)              803840    \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 1024)              4096      \n","_________________________________________________________________\n","activation (Activation)      (None, 1024)              0         \n","_________________________________________________________________\n","dense_9 (Dense)              (None, 1024)              1049600   \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 1024)              4096      \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 1024)              0         \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 1024)              1049600   \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 1024)              4096      \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 1024)              0         \n","_________________________________________________________________\n","flatten_5 (Flatten)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 10)                10250     \n","=================================================================\n","Total params: 2,925,578\n","Trainable params: 2,919,434\n","Non-trainable params: 6,144\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"izQBrVW6KYr3"},"source":["BN Model을 학습해 보겠습니다. Generalization 성능이 올라갔나요?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bL2oakRaKZ4y","executionInfo":{"status":"ok","timestamp":1619188850305,"user_tz":-540,"elapsed":135530,"user":{"displayName":"김태영","photoUrl":"","userId":"02983489978232498818"}},"outputId":"d60a1794-99b8-4927-cec0-fb33cb881f2c"},"source":["bn_model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=keras.optimizers.Adadelta(),\n","              metrics=['accuracy'])\n","bn_model_history=bn_model.fit(large_x_train, large_y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_validation, y_validation))\n","\n","score = bn_model.evaluate(x_test, y_test, verbose=0)\n","print('BN model Test loss:', score[0])\n","print('BN model Test accuracy:', score[1])"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","72/72 [==============================] - 1s 8ms/step - loss: 2.6078 - accuracy: 0.1379 - val_loss: 2.2660 - val_accuracy: 0.1000\n","Epoch 2/100\n","72/72 [==============================] - 0s 6ms/step - loss: 2.3879 - accuracy: 0.1923 - val_loss: 2.2087 - val_accuracy: 0.1350\n","Epoch 3/100\n","72/72 [==============================] - 0s 5ms/step - loss: 2.1855 - accuracy: 0.2469 - val_loss: 2.0769 - val_accuracy: 0.2300\n","Epoch 4/100\n","72/72 [==============================] - 0s 5ms/step - loss: 2.0530 - accuracy: 0.2913 - val_loss: 1.9075 - val_accuracy: 0.3600\n","Epoch 5/100\n","72/72 [==============================] - 0s 5ms/step - loss: 1.9147 - accuracy: 0.3343 - val_loss: 1.7469 - val_accuracy: 0.4200\n","Epoch 6/100\n","72/72 [==============================] - 0s 5ms/step - loss: 1.8062 - accuracy: 0.3917 - val_loss: 1.6100 - val_accuracy: 0.4950\n","Epoch 7/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.6573 - accuracy: 0.4627 - val_loss: 1.4974 - val_accuracy: 0.5400\n","Epoch 8/100\n","72/72 [==============================] - 0s 5ms/step - loss: 1.5902 - accuracy: 0.4868 - val_loss: 1.4001 - val_accuracy: 0.5550\n","Epoch 9/100\n","72/72 [==============================] - 0s 5ms/step - loss: 1.4918 - accuracy: 0.5329 - val_loss: 1.3170 - val_accuracy: 0.6050\n","Epoch 10/100\n","72/72 [==============================] - 0s 5ms/step - loss: 1.3998 - accuracy: 0.5813 - val_loss: 1.2423 - val_accuracy: 0.6450\n","Epoch 11/100\n","72/72 [==============================] - 0s 5ms/step - loss: 1.3013 - accuracy: 0.6198 - val_loss: 1.1778 - val_accuracy: 0.6550\n","Epoch 12/100\n","72/72 [==============================] - 0s 5ms/step - loss: 1.2328 - accuracy: 0.6464 - val_loss: 1.1215 - val_accuracy: 0.7000\n","Epoch 13/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.1944 - accuracy: 0.6742 - val_loss: 1.0709 - val_accuracy: 0.7000\n","Epoch 14/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.1574 - accuracy: 0.6740 - val_loss: 1.0252 - val_accuracy: 0.7000\n","Epoch 15/100\n","72/72 [==============================] - 0s 5ms/step - loss: 1.0776 - accuracy: 0.7159 - val_loss: 0.9823 - val_accuracy: 0.7300\n","Epoch 16/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.9993 - accuracy: 0.7332 - val_loss: 0.9445 - val_accuracy: 0.7450\n","Epoch 17/100\n","72/72 [==============================] - 0s 5ms/step - loss: 1.0049 - accuracy: 0.7339 - val_loss: 0.9110 - val_accuracy: 0.7650\n","Epoch 18/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.9694 - accuracy: 0.7502 - val_loss: 0.8795 - val_accuracy: 0.7650\n","Epoch 19/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.9297 - accuracy: 0.7477 - val_loss: 0.8506 - val_accuracy: 0.7650\n","Epoch 20/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.8916 - accuracy: 0.7617 - val_loss: 0.8245 - val_accuracy: 0.7750\n","Epoch 21/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.8549 - accuracy: 0.7708 - val_loss: 0.8009 - val_accuracy: 0.7750\n","Epoch 22/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.7942 - accuracy: 0.8129 - val_loss: 0.7782 - val_accuracy: 0.7800\n","Epoch 23/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.8362 - accuracy: 0.7787 - val_loss: 0.7570 - val_accuracy: 0.7900\n","Epoch 24/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.7723 - accuracy: 0.7990 - val_loss: 0.7383 - val_accuracy: 0.7900\n","Epoch 25/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.7392 - accuracy: 0.8214 - val_loss: 0.7215 - val_accuracy: 0.7900\n","Epoch 26/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.7163 - accuracy: 0.8390 - val_loss: 0.7045 - val_accuracy: 0.8000\n","Epoch 27/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.7154 - accuracy: 0.8245 - val_loss: 0.6884 - val_accuracy: 0.8000\n","Epoch 28/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.6844 - accuracy: 0.8396 - val_loss: 0.6739 - val_accuracy: 0.8200\n","Epoch 29/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.6668 - accuracy: 0.8358 - val_loss: 0.6593 - val_accuracy: 0.8200\n","Epoch 30/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.6318 - accuracy: 0.8588 - val_loss: 0.6467 - val_accuracy: 0.8150\n","Epoch 31/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.6219 - accuracy: 0.8563 - val_loss: 0.6347 - val_accuracy: 0.8200\n","Epoch 32/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.5940 - accuracy: 0.8696 - val_loss: 0.6231 - val_accuracy: 0.8250\n","Epoch 33/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.5989 - accuracy: 0.8642 - val_loss: 0.6121 - val_accuracy: 0.8250\n","Epoch 34/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.5811 - accuracy: 0.8602 - val_loss: 0.6021 - val_accuracy: 0.8300\n","Epoch 35/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.5603 - accuracy: 0.8733 - val_loss: 0.5921 - val_accuracy: 0.8350\n","Epoch 36/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.5703 - accuracy: 0.8591 - val_loss: 0.5823 - val_accuracy: 0.8350\n","Epoch 37/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.5325 - accuracy: 0.8753 - val_loss: 0.5739 - val_accuracy: 0.8400\n","Epoch 38/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.5438 - accuracy: 0.8778 - val_loss: 0.5663 - val_accuracy: 0.8450\n","Epoch 39/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.5498 - accuracy: 0.8738 - val_loss: 0.5578 - val_accuracy: 0.8500\n","Epoch 40/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.5167 - accuracy: 0.8868 - val_loss: 0.5496 - val_accuracy: 0.8500\n","Epoch 41/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.5061 - accuracy: 0.8821 - val_loss: 0.5421 - val_accuracy: 0.8600\n","Epoch 42/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.4679 - accuracy: 0.9019 - val_loss: 0.5361 - val_accuracy: 0.8600\n","Epoch 43/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.4879 - accuracy: 0.8855 - val_loss: 0.5294 - val_accuracy: 0.8600\n","Epoch 44/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.4550 - accuracy: 0.8964 - val_loss: 0.5238 - val_accuracy: 0.8600\n","Epoch 45/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.9016 - val_loss: 0.5177 - val_accuracy: 0.8550\n","Epoch 46/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.4676 - accuracy: 0.8843 - val_loss: 0.5117 - val_accuracy: 0.8550\n","Epoch 47/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.4386 - accuracy: 0.9012 - val_loss: 0.5067 - val_accuracy: 0.8550\n","Epoch 48/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.4438 - accuracy: 0.9082 - val_loss: 0.5013 - val_accuracy: 0.8550\n","Epoch 49/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.4548 - accuracy: 0.8930 - val_loss: 0.4959 - val_accuracy: 0.8550\n","Epoch 50/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.4097 - accuracy: 0.9142 - val_loss: 0.4899 - val_accuracy: 0.8550\n","Epoch 51/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.4065 - accuracy: 0.9176 - val_loss: 0.4854 - val_accuracy: 0.8550\n","Epoch 52/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.4091 - accuracy: 0.9157 - val_loss: 0.4800 - val_accuracy: 0.8550\n","Epoch 53/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.9036 - val_loss: 0.4759 - val_accuracy: 0.8550\n","Epoch 54/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.3836 - accuracy: 0.9247 - val_loss: 0.4718 - val_accuracy: 0.8550\n","Epoch 55/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.3823 - accuracy: 0.9149 - val_loss: 0.4687 - val_accuracy: 0.8550\n","Epoch 56/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.3829 - accuracy: 0.9158 - val_loss: 0.4645 - val_accuracy: 0.8550\n","Epoch 57/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.3775 - accuracy: 0.9211 - val_loss: 0.4605 - val_accuracy: 0.8550\n","Epoch 58/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.3881 - accuracy: 0.9049 - val_loss: 0.4562 - val_accuracy: 0.8550\n","Epoch 59/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.3360 - accuracy: 0.9379 - val_loss: 0.4536 - val_accuracy: 0.8550\n","Epoch 60/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.3580 - accuracy: 0.9168 - val_loss: 0.4502 - val_accuracy: 0.8550\n","Epoch 61/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.3617 - accuracy: 0.9231 - val_loss: 0.4463 - val_accuracy: 0.8600\n","Epoch 62/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.3407 - accuracy: 0.9256 - val_loss: 0.4435 - val_accuracy: 0.8650\n","Epoch 63/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.3308 - accuracy: 0.9309 - val_loss: 0.4407 - val_accuracy: 0.8650\n","Epoch 64/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.3611 - accuracy: 0.9207 - val_loss: 0.4376 - val_accuracy: 0.8650\n","Epoch 65/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.3297 - accuracy: 0.9349 - val_loss: 0.4351 - val_accuracy: 0.8650\n","Epoch 66/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.3376 - accuracy: 0.9333 - val_loss: 0.4321 - val_accuracy: 0.8700\n","Epoch 67/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.3289 - accuracy: 0.9227 - val_loss: 0.4293 - val_accuracy: 0.8700\n","Epoch 68/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.3144 - accuracy: 0.9340 - val_loss: 0.4263 - val_accuracy: 0.8700\n","Epoch 69/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2986 - accuracy: 0.9421 - val_loss: 0.4243 - val_accuracy: 0.8700\n","Epoch 70/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.3035 - accuracy: 0.9412 - val_loss: 0.4215 - val_accuracy: 0.8700\n","Epoch 71/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2941 - accuracy: 0.9348 - val_loss: 0.4190 - val_accuracy: 0.8700\n","Epoch 72/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2940 - accuracy: 0.9412 - val_loss: 0.4160 - val_accuracy: 0.8700\n","Epoch 73/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2930 - accuracy: 0.9487 - val_loss: 0.4134 - val_accuracy: 0.8700\n","Epoch 74/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2914 - accuracy: 0.9342 - val_loss: 0.4116 - val_accuracy: 0.8750\n","Epoch 75/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2946 - accuracy: 0.9401 - val_loss: 0.4090 - val_accuracy: 0.8700\n","Epoch 76/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2855 - accuracy: 0.9400 - val_loss: 0.4074 - val_accuracy: 0.8700\n","Epoch 77/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2638 - accuracy: 0.9448 - val_loss: 0.4055 - val_accuracy: 0.8800\n","Epoch 78/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2795 - accuracy: 0.9489 - val_loss: 0.4029 - val_accuracy: 0.8850\n","Epoch 79/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2694 - accuracy: 0.9465 - val_loss: 0.4004 - val_accuracy: 0.8900\n","Epoch 80/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2611 - accuracy: 0.9480 - val_loss: 0.3987 - val_accuracy: 0.8850\n","Epoch 81/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2514 - accuracy: 0.9537 - val_loss: 0.3974 - val_accuracy: 0.8900\n","Epoch 82/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2730 - accuracy: 0.9482 - val_loss: 0.3957 - val_accuracy: 0.8900\n","Epoch 83/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2580 - accuracy: 0.9503 - val_loss: 0.3935 - val_accuracy: 0.8950\n","Epoch 84/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2483 - accuracy: 0.9530 - val_loss: 0.3917 - val_accuracy: 0.8950\n","Epoch 85/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2458 - accuracy: 0.9463 - val_loss: 0.3898 - val_accuracy: 0.8950\n","Epoch 86/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2338 - accuracy: 0.9546 - val_loss: 0.3886 - val_accuracy: 0.8950\n","Epoch 87/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2529 - accuracy: 0.9463 - val_loss: 0.3864 - val_accuracy: 0.9000\n","Epoch 88/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2344 - accuracy: 0.9538 - val_loss: 0.3848 - val_accuracy: 0.9000\n","Epoch 89/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2316 - accuracy: 0.9600 - val_loss: 0.3836 - val_accuracy: 0.9000\n","Epoch 90/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2384 - accuracy: 0.9519 - val_loss: 0.3823 - val_accuracy: 0.9000\n","Epoch 91/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2252 - accuracy: 0.9525 - val_loss: 0.3806 - val_accuracy: 0.9000\n","Epoch 92/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2056 - accuracy: 0.9664 - val_loss: 0.3785 - val_accuracy: 0.9000\n","Epoch 93/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2254 - accuracy: 0.9623 - val_loss: 0.3767 - val_accuracy: 0.9000\n","Epoch 94/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2307 - accuracy: 0.9508 - val_loss: 0.3763 - val_accuracy: 0.9000\n","Epoch 95/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2386 - accuracy: 0.9514 - val_loss: 0.3757 - val_accuracy: 0.9000\n","Epoch 96/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2188 - accuracy: 0.9616 - val_loss: 0.3739 - val_accuracy: 0.9000\n","Epoch 97/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2364 - accuracy: 0.9526 - val_loss: 0.3732 - val_accuracy: 0.9000\n","Epoch 98/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2251 - accuracy: 0.9565 - val_loss: 0.3714 - val_accuracy: 0.9000\n","Epoch 99/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.1880 - accuracy: 0.9722 - val_loss: 0.3696 - val_accuracy: 0.9000\n","Epoch 100/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2079 - accuracy: 0.9629 - val_loss: 0.3682 - val_accuracy: 0.9000\n","BN model Test loss: 0.3707224428653717\n","BN model Test accuracy: 0.891700029373169\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5fDPwaFsJ47I"},"source":["##4.4 Final Model\n","지금까지 썼던 Regularization 기법들을 종합선물세트로 적용해 봅시다. 다음과 같은 Final model을 만들어 보세요.\n","\n","| Layer (type) | Output Shape | Param # |\n","|------|------|------|\n","| Flatten | (None, 784) | 0 |\n","| Dense | (None, 1024) | 803840 |\n","| BatchNormalization | (None, 1024) | 4096 |\n","| Activation | (None, 1024) | 0 |\n","| Dense | (None, 1024) | 1049600 |\n","| BatchNormalization | (None, 1024) | 4096 |\n","| Activation | (None, 1024) | 0 |\n","| Dense | (None, 1024) | 1049600 |\n","| BatchNormalization | (None, 1024) | 4096 |\n","| Activation | (None, 1024) | 0 |\n","| Dropout | (None, 1024) | 0 |\n","| Flatten | (None, 1024) | 0 |\n","| Dense | (None, 10) | 10250 |"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z8ppnPcELADo","executionInfo":{"status":"ok","timestamp":1619188850306,"user_tz":-540,"elapsed":135528,"user":{"displayName":"김태영","photoUrl":"","userId":"02983489978232498818"}},"outputId":"b618e936-fd20-48b6-c434-f3676d34004b"},"source":["final_model = Sequential()\n","### START CODE HERE ###\n","final_model.add(Flatten(input_shape=(28,28)))\n","final_model.add(Dense(1024))\n","final_model.add(BatchNormalization())\n","final_model.add(Activation('relu'))\n","final_model.add(Dense(1024))\n","final_model.add(BatchNormalization())\n","final_model.add(Activation('relu'))\n","final_model.add(Dense(1024))\n","final_model.add(BatchNormalization())\n","final_model.add(Activation('relu'))\n","final_model.add(Dropout(0.3))\n","final_model.add(Flatten(input_shape=(1024,)))\n","final_model.add(Dense(10,activation='softmax'))\n","### END CODE HERE ###\n","final_model.summary()\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","flatten_6 (Flatten)          (None, 784)               0         \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 1024)              803840    \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 1024)              4096      \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 1024)              0         \n","_________________________________________________________________\n","dense_13 (Dense)             (None, 1024)              1049600   \n","_________________________________________________________________\n","batch_normalization_4 (Batch (None, 1024)              4096      \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 1024)              0         \n","_________________________________________________________________\n","dense_14 (Dense)             (None, 1024)              1049600   \n","_________________________________________________________________\n","batch_normalization_5 (Batch (None, 1024)              4096      \n","_________________________________________________________________\n","activation_5 (Activation)    (None, 1024)              0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","flatten_7 (Flatten)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_15 (Dense)             (None, 10)                10250     \n","=================================================================\n","Total params: 2,925,578\n","Trainable params: 2,919,434\n","Non-trainable params: 6,144\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ocok8VnoLcb4"},"source":["Final Model을 학습해 보겠습니다. Generalization 성능이 올라갔나요?"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A-bFRiHtLdVe","executionInfo":{"status":"ok","timestamp":1619188892837,"user_tz":-540,"elapsed":178056,"user":{"displayName":"김태영","photoUrl":"","userId":"02983489978232498818"}},"outputId":"dbc768b2-3489-4220-9fa3-17a5f61aa051"},"source":["final_model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=keras.optimizers.Adadelta(),\n","              metrics=['accuracy'])\n","final_model_history=final_model.fit(large_x_train, large_y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_validation, y_validation))\n","\n","score = final_model.evaluate(x_test, y_test, verbose=0)\n","print('Final model Test loss:', score[0])\n","print('Final model Test accuracy:', score[1])"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","72/72 [==============================] - 1s 8ms/step - loss: 2.8081 - accuracy: 0.1085 - val_loss: 2.3281 - val_accuracy: 0.0850\n","Epoch 2/100\n","72/72 [==============================] - 0s 6ms/step - loss: 2.6398 - accuracy: 0.1402 - val_loss: 2.3302 - val_accuracy: 0.1100\n","Epoch 3/100\n","72/72 [==============================] - 0s 5ms/step - loss: 2.4987 - accuracy: 0.1698 - val_loss: 2.2733 - val_accuracy: 0.1750\n","Epoch 4/100\n","72/72 [==============================] - 0s 5ms/step - loss: 2.3436 - accuracy: 0.2279 - val_loss: 2.1734 - val_accuracy: 0.1900\n","Epoch 5/100\n","72/72 [==============================] - 0s 5ms/step - loss: 2.1989 - accuracy: 0.2541 - val_loss: 2.0543 - val_accuracy: 0.2450\n","Epoch 6/100\n","72/72 [==============================] - 0s 5ms/step - loss: 2.1099 - accuracy: 0.2931 - val_loss: 1.9379 - val_accuracy: 0.2950\n","Epoch 7/100\n","72/72 [==============================] - 0s 5ms/step - loss: 1.9821 - accuracy: 0.3365 - val_loss: 1.8284 - val_accuracy: 0.3250\n","Epoch 8/100\n","72/72 [==============================] - 0s 5ms/step - loss: 1.8730 - accuracy: 0.3648 - val_loss: 1.7289 - val_accuracy: 0.3850\n","Epoch 9/100\n","72/72 [==============================] - 0s 5ms/step - loss: 1.7818 - accuracy: 0.4009 - val_loss: 1.6358 - val_accuracy: 0.4200\n","Epoch 10/100\n","72/72 [==============================] - 0s 5ms/step - loss: 1.7043 - accuracy: 0.4238 - val_loss: 1.5480 - val_accuracy: 0.4800\n","Epoch 11/100\n","72/72 [==============================] - 0s 5ms/step - loss: 1.5975 - accuracy: 0.4624 - val_loss: 1.4689 - val_accuracy: 0.5100\n","Epoch 12/100\n","72/72 [==============================] - 0s 5ms/step - loss: 1.5598 - accuracy: 0.4751 - val_loss: 1.3949 - val_accuracy: 0.5400\n","Epoch 13/100\n","72/72 [==============================] - 0s 5ms/step - loss: 1.5239 - accuracy: 0.4899 - val_loss: 1.3318 - val_accuracy: 0.5600\n","Epoch 14/100\n","72/72 [==============================] - 0s 5ms/step - loss: 1.4020 - accuracy: 0.5500 - val_loss: 1.2713 - val_accuracy: 0.6000\n","Epoch 15/100\n","72/72 [==============================] - 0s 5ms/step - loss: 1.3352 - accuracy: 0.5802 - val_loss: 1.2179 - val_accuracy: 0.6450\n","Epoch 16/100\n","72/72 [==============================] - 0s 5ms/step - loss: 1.2531 - accuracy: 0.6000 - val_loss: 1.1664 - val_accuracy: 0.6700\n","Epoch 17/100\n","72/72 [==============================] - 0s 5ms/step - loss: 1.2391 - accuracy: 0.6227 - val_loss: 1.1201 - val_accuracy: 0.6900\n","Epoch 18/100\n","72/72 [==============================] - 0s 5ms/step - loss: 1.2081 - accuracy: 0.6074 - val_loss: 1.0772 - val_accuracy: 0.7100\n","Epoch 19/100\n","72/72 [==============================] - 0s 5ms/step - loss: 1.1548 - accuracy: 0.6304 - val_loss: 1.0387 - val_accuracy: 0.7150\n","Epoch 20/100\n","72/72 [==============================] - 0s 5ms/step - loss: 1.1172 - accuracy: 0.6542 - val_loss: 1.0032 - val_accuracy: 0.7350\n","Epoch 21/100\n","72/72 [==============================] - 0s 5ms/step - loss: 1.0673 - accuracy: 0.6784 - val_loss: 0.9702 - val_accuracy: 0.7400\n","Epoch 22/100\n","72/72 [==============================] - 0s 5ms/step - loss: 1.0664 - accuracy: 0.6619 - val_loss: 0.9394 - val_accuracy: 0.7550\n","Epoch 23/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.0102 - accuracy: 0.6894 - val_loss: 0.9100 - val_accuracy: 0.7650\n","Epoch 24/100\n","72/72 [==============================] - 0s 5ms/step - loss: 1.0194 - accuracy: 0.6925 - val_loss: 0.8834 - val_accuracy: 0.7750\n","Epoch 25/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.9468 - accuracy: 0.7219 - val_loss: 0.8581 - val_accuracy: 0.7850\n","Epoch 26/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.9170 - accuracy: 0.7374 - val_loss: 0.8355 - val_accuracy: 0.7850\n","Epoch 27/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.8896 - accuracy: 0.7401 - val_loss: 0.8127 - val_accuracy: 0.8000\n","Epoch 28/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.8680 - accuracy: 0.7390 - val_loss: 0.7928 - val_accuracy: 0.8000\n","Epoch 29/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.8826 - accuracy: 0.7399 - val_loss: 0.7751 - val_accuracy: 0.8000\n","Epoch 30/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.8107 - accuracy: 0.7596 - val_loss: 0.7569 - val_accuracy: 0.8050\n","Epoch 31/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.7926 - accuracy: 0.7636 - val_loss: 0.7388 - val_accuracy: 0.8050\n","Epoch 32/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.8072 - accuracy: 0.7785 - val_loss: 0.7237 - val_accuracy: 0.8150\n","Epoch 33/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.7608 - accuracy: 0.7802 - val_loss: 0.7083 - val_accuracy: 0.8150\n","Epoch 34/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.7775 - accuracy: 0.7665 - val_loss: 0.6932 - val_accuracy: 0.8200\n","Epoch 35/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.7376 - accuracy: 0.7953 - val_loss: 0.6805 - val_accuracy: 0.8250\n","Epoch 36/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.7189 - accuracy: 0.7943 - val_loss: 0.6680 - val_accuracy: 0.8350\n","Epoch 37/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.6978 - accuracy: 0.8085 - val_loss: 0.6558 - val_accuracy: 0.8350\n","Epoch 38/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.6745 - accuracy: 0.8161 - val_loss: 0.6427 - val_accuracy: 0.8350\n","Epoch 39/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.6686 - accuracy: 0.8240 - val_loss: 0.6319 - val_accuracy: 0.8400\n","Epoch 40/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.6733 - accuracy: 0.8062 - val_loss: 0.6215 - val_accuracy: 0.8450\n","Epoch 41/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.6549 - accuracy: 0.8099 - val_loss: 0.6114 - val_accuracy: 0.8450\n","Epoch 42/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.6053 - accuracy: 0.8349 - val_loss: 0.6012 - val_accuracy: 0.8450\n","Epoch 43/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.6356 - accuracy: 0.8202 - val_loss: 0.5912 - val_accuracy: 0.8450\n","Epoch 44/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.6196 - accuracy: 0.8185 - val_loss: 0.5827 - val_accuracy: 0.8450\n","Epoch 45/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.6265 - accuracy: 0.8271 - val_loss: 0.5740 - val_accuracy: 0.8450\n","Epoch 46/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.5923 - accuracy: 0.8422 - val_loss: 0.5672 - val_accuracy: 0.8550\n","Epoch 47/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.5810 - accuracy: 0.8422 - val_loss: 0.5591 - val_accuracy: 0.8550\n","Epoch 48/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.5549 - accuracy: 0.8540 - val_loss: 0.5507 - val_accuracy: 0.8600\n","Epoch 49/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.5719 - accuracy: 0.8441 - val_loss: 0.5436 - val_accuracy: 0.8600\n","Epoch 50/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.5767 - accuracy: 0.8357 - val_loss: 0.5364 - val_accuracy: 0.8650\n","Epoch 51/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.5531 - accuracy: 0.8372 - val_loss: 0.5309 - val_accuracy: 0.8700\n","Epoch 52/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.5372 - accuracy: 0.8484 - val_loss: 0.5231 - val_accuracy: 0.8700\n","Epoch 53/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.5251 - accuracy: 0.8544 - val_loss: 0.5178 - val_accuracy: 0.8700\n","Epoch 54/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.5281 - accuracy: 0.8499 - val_loss: 0.5122 - val_accuracy: 0.8750\n","Epoch 55/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.5111 - accuracy: 0.8657 - val_loss: 0.5060 - val_accuracy: 0.8750\n","Epoch 56/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.4917 - accuracy: 0.8760 - val_loss: 0.5005 - val_accuracy: 0.8800\n","Epoch 57/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.4969 - accuracy: 0.8627 - val_loss: 0.4960 - val_accuracy: 0.8850\n","Epoch 58/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.4969 - accuracy: 0.8614 - val_loss: 0.4909 - val_accuracy: 0.8850\n","Epoch 59/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.8805 - val_loss: 0.4867 - val_accuracy: 0.8850\n","Epoch 60/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.8717 - val_loss: 0.4824 - val_accuracy: 0.8900\n","Epoch 61/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.4860 - accuracy: 0.8659 - val_loss: 0.4782 - val_accuracy: 0.8950\n","Epoch 62/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.4800 - accuracy: 0.8774 - val_loss: 0.4734 - val_accuracy: 0.9000\n","Epoch 63/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.8842 - val_loss: 0.4692 - val_accuracy: 0.8950\n","Epoch 64/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.4195 - accuracy: 0.8911 - val_loss: 0.4645 - val_accuracy: 0.8950\n","Epoch 65/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.4608 - accuracy: 0.8636 - val_loss: 0.4604 - val_accuracy: 0.9000\n","Epoch 66/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.4606 - accuracy: 0.8807 - val_loss: 0.4564 - val_accuracy: 0.8950\n","Epoch 67/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.4240 - accuracy: 0.8846 - val_loss: 0.4530 - val_accuracy: 0.9000\n","Epoch 68/100\n","72/72 [==============================] - 1s 7ms/step - loss: 0.4080 - accuracy: 0.9035 - val_loss: 0.4497 - val_accuracy: 0.9000\n","Epoch 69/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.4519 - accuracy: 0.8775 - val_loss: 0.4465 - val_accuracy: 0.9050\n","Epoch 70/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.4171 - accuracy: 0.9019 - val_loss: 0.4431 - val_accuracy: 0.9050\n","Epoch 71/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.3911 - accuracy: 0.9051 - val_loss: 0.4400 - val_accuracy: 0.9050\n","Epoch 72/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.4039 - accuracy: 0.8940 - val_loss: 0.4364 - val_accuracy: 0.9050\n","Epoch 73/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.3968 - accuracy: 0.8948 - val_loss: 0.4332 - val_accuracy: 0.9050\n","Epoch 74/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.3841 - accuracy: 0.9039 - val_loss: 0.4294 - val_accuracy: 0.9050\n","Epoch 75/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.3937 - accuracy: 0.9045 - val_loss: 0.4259 - val_accuracy: 0.9050\n","Epoch 76/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.3798 - accuracy: 0.8999 - val_loss: 0.4236 - val_accuracy: 0.9100\n","Epoch 77/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.3891 - accuracy: 0.8980 - val_loss: 0.4208 - val_accuracy: 0.9100\n","Epoch 78/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.3631 - accuracy: 0.9102 - val_loss: 0.4174 - val_accuracy: 0.9100\n","Epoch 79/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.3511 - accuracy: 0.9101 - val_loss: 0.4152 - val_accuracy: 0.9100\n","Epoch 80/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.3585 - accuracy: 0.9082 - val_loss: 0.4123 - val_accuracy: 0.9100\n","Epoch 81/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.3859 - accuracy: 0.9057 - val_loss: 0.4105 - val_accuracy: 0.9100\n","Epoch 82/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.3564 - accuracy: 0.9101 - val_loss: 0.4079 - val_accuracy: 0.9100\n","Epoch 83/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.3504 - accuracy: 0.9120 - val_loss: 0.4050 - val_accuracy: 0.9100\n","Epoch 84/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.3346 - accuracy: 0.9226 - val_loss: 0.4031 - val_accuracy: 0.9100\n","Epoch 85/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.3410 - accuracy: 0.9135 - val_loss: 0.4012 - val_accuracy: 0.9150\n","Epoch 86/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.3190 - accuracy: 0.9169 - val_loss: 0.3991 - val_accuracy: 0.9150\n","Epoch 87/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.3273 - accuracy: 0.9226 - val_loss: 0.3965 - val_accuracy: 0.9150\n","Epoch 88/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.3149 - accuracy: 0.9327 - val_loss: 0.3945 - val_accuracy: 0.9150\n","Epoch 89/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.3236 - accuracy: 0.9230 - val_loss: 0.3917 - val_accuracy: 0.9150\n","Epoch 90/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.3265 - accuracy: 0.9188 - val_loss: 0.3892 - val_accuracy: 0.9150\n","Epoch 91/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.3218 - accuracy: 0.9093 - val_loss: 0.3867 - val_accuracy: 0.9150\n","Epoch 92/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.3063 - accuracy: 0.9205 - val_loss: 0.3858 - val_accuracy: 0.9150\n","Epoch 93/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.3408 - accuracy: 0.9206 - val_loss: 0.3848 - val_accuracy: 0.9150\n","Epoch 94/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.3223 - accuracy: 0.9270 - val_loss: 0.3830 - val_accuracy: 0.9200\n","Epoch 95/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.3203 - accuracy: 0.9074 - val_loss: 0.3805 - val_accuracy: 0.9200\n","Epoch 96/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.3017 - accuracy: 0.9229 - val_loss: 0.3785 - val_accuracy: 0.9200\n","Epoch 97/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.3159 - accuracy: 0.9220 - val_loss: 0.3771 - val_accuracy: 0.9200\n","Epoch 98/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.3020 - accuracy: 0.9262 - val_loss: 0.3757 - val_accuracy: 0.9200\n","Epoch 99/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.3149 - accuracy: 0.9161 - val_loss: 0.3743 - val_accuracy: 0.9200\n","Epoch 100/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2722 - accuracy: 0.9407 - val_loss: 0.3728 - val_accuracy: 0.9200\n","Final model Test loss: 0.3852810263633728\n","Final model Test accuracy: 0.8894000053405762\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"cPR3nEMAL4Yd"},"source":["(optional) Training data가 늘어나면 regularization 효과가 나는 것을 보였습니다. 쉽게 training data를 늘릴 수 있는 방법은 data augmentation 입니다. 이 방법은 기존 training data를 적절히 rotating, flipping, scaling, shifting 하여 training data 수를 늘리는 것입니다. data augmentation의 regularization 효과를 테스트해 보세요. 또한 뉴럴 네트워크의 노드 개수나 층수를 바꿔서 성능을 올려보는 것도 테스트해보세요."]},{"cell_type":"markdown","metadata":{"id":"KAhQvUTXzWuN"},"source":["필요한 Libary Import 하기"]},{"cell_type":"code","metadata":{"id":"UIcJheDkyDhX","executionInfo":{"status":"ok","timestamp":1619188892837,"user_tz":-540,"elapsed":178054,"user":{"displayName":"김태영","photoUrl":"","userId":"02983489978232498818"}}},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from __future__ import print_function\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, BatchNormalization, Activation, Flatten\n","from keras import backend as K\n","from matplotlib import pyplot"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-x1fD2AT35dO"},"source":["데이터 생성 ImageDataGenerator를 이용하여 Data Augmentation 구현  \n","\n","Rotations - 90  \n","horizontal_flip - 수평방향으로 뒤집기  \n","vertical_flip - 수직방향으로 뒤집기  \n","width_shift_range - 가로 방향으로 이동  \n","height_shift_range - 세로 방향으로 이동\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":590},"id":"WFqmAzH5yfLY","executionInfo":{"status":"ok","timestamp":1619188894329,"user_tz":-540,"elapsed":179543,"user":{"displayName":"김태영","photoUrl":"","userId":"02983489978232498818"}},"outputId":"b8446ae4-4a72-44cd-dc27-ad7a0202af23"},"source":["batch_size = 28\n","num_classes = 10\n","epochs = 100\n","\n","# input image dimensions\n","img_rows, img_cols = 28, 28\n","\n","# the data, split between train and test sets\n","(X_train, Y_train), (x_test,y_test) = mnist.load_data()\n","\n","# 아까와 마찬가지 방법으로 split\n","large_x_train_agg = X_train[200:2200,:,:]\n","large_y_train_agg = Y_train[200:2200]\n","\n","large_y_train_agg = Y_train[200:2200]\n","\n","if K.image_data_format() == 'channels_first':\n","    large_x_train_agg = large_x_train_agg.reshape(large_x_train_agg.shape[0], 1, img_rows, img_cols)\n","    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n","    input_shape = (1, img_rows, img_cols)\n","else:\n","    large_x_train_agg = large_x_train_agg.reshape(large_x_train_agg.shape[0], img_rows, img_cols, 1)\n","    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n","    input_shape = (img_rows, img_cols, 1)\n","\n","# convert from int to float\n","large_x_train_agg = large_x_train_agg.astype('float32')\n","x_test = x_test.astype('float32')\n","\n","# plot을 위한 ImageDataGenerator 생성\n","datagen1 = ImageDataGenerator()\n","datagen1.fit(large_x_train_agg)\n","\n","# configure batch size and retrieve one batch of images\n","for X_batch, y_batch in datagen1.flow(large_x_train_agg, large_y_train_agg, batch_size=9):\n","\t# create a grid of 3x3 images\n","\tfor i in range(0, 9):\n","\t\tpyplot.subplot(330 + 1 + i)\n","\t\tpyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n","\t# show the plot\n","\tpyplot.show()\n","\tbreak\n","\n","# define data preparation\n","shift = 0.2\n","\n","# define data preparation\n","datagen = ImageDataGenerator(rotation_range=90,\n","                             horizontal_flip=True, vertical_flip=True,\n","                             width_shift_range=shift, height_shift_range=shift)\n","\n","# fit parameters from data\n","datagen.fit(large_x_train_agg)\n","\n","# configure batch size and retrieve one batch of images\n","for X_batch, y_batch in datagen.flow(large_x_train_agg, large_y_train_agg, batch_size=9):\n","\t# create a grid of 3x3 images\n","\tfor i in range(0, 9):\n","\t\tpyplot.subplot(330 + 1 + i)\n","\t\tpyplot.imshow(X_batch[i].reshape(28, 28), cmap=pyplot.get_cmap('gray'))\n","\t# show the plot\n","\tpyplot.show()\n","\tbreak\n","\n","large_x_train_agg /= 255\n","x_test /= 255\n","\n","# convert class vectors to binary class matrices\n","large_y_train_agg = keras.utils.to_categorical(large_y_train_agg, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","print(\"large_x_train_agg shape:\", large_x_train_agg.shape)\n","print(\"large_y_train_agg shape:\", large_y_train_agg.shape)\n","print(\"x_test shape:\", x_test.shape)\n","print(\"y_test shape:\", y_test.shape)"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 9 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 9 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"stream","text":["large_x_train_agg shape: (2000, 28, 28, 1)\n","large_y_train_agg shape: (2000, 10)\n","x_test shape: (10000, 28, 28, 1)\n","y_test shape: (10000, 10)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2a6l3iRc6rvD"},"source":["동일한 모델을 이용하여 Training"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-6LvJqF3yfqr","executionInfo":{"status":"ok","timestamp":1619188935052,"user_tz":-540,"elapsed":220263,"user":{"displayName":"김태영","photoUrl":"","userId":"02983489978232498818"}},"outputId":"95bb2943-1f0c-4cb1-b185-2171116a49d5"},"source":["final_model_history=final_model.fit(large_x_train_agg, large_y_train_agg,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_validation, y_validation))\n","\n","score = final_model.evaluate(x_test, y_test, verbose=0)\n","print('Final model Test loss:', score[0])\n","print('Final model Test accuracy:', score[1])"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2932 - accuracy: 0.9265 - val_loss: 0.3708 - val_accuracy: 0.9200\n","Epoch 2/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2981 - accuracy: 0.9305 - val_loss: 0.3693 - val_accuracy: 0.9200\n","Epoch 3/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2835 - accuracy: 0.9285 - val_loss: 0.3685 - val_accuracy: 0.9200\n","Epoch 4/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2765 - accuracy: 0.9310 - val_loss: 0.3669 - val_accuracy: 0.9200\n","Epoch 5/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2807 - accuracy: 0.9370 - val_loss: 0.3652 - val_accuracy: 0.9200\n","Epoch 6/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2788 - accuracy: 0.9305 - val_loss: 0.3634 - val_accuracy: 0.9200\n","Epoch 7/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2898 - accuracy: 0.9240 - val_loss: 0.3617 - val_accuracy: 0.9200\n","Epoch 8/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2812 - accuracy: 0.9345 - val_loss: 0.3600 - val_accuracy: 0.9200\n","Epoch 9/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2788 - accuracy: 0.9325 - val_loss: 0.3579 - val_accuracy: 0.9200\n","Epoch 10/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2810 - accuracy: 0.9335 - val_loss: 0.3575 - val_accuracy: 0.9200\n","Epoch 11/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2708 - accuracy: 0.9360 - val_loss: 0.3569 - val_accuracy: 0.9200\n","Epoch 12/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2641 - accuracy: 0.9385 - val_loss: 0.3550 - val_accuracy: 0.9200\n","Epoch 13/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2653 - accuracy: 0.9330 - val_loss: 0.3533 - val_accuracy: 0.9200\n","Epoch 14/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2628 - accuracy: 0.9430 - val_loss: 0.3526 - val_accuracy: 0.9200\n","Epoch 15/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2570 - accuracy: 0.9430 - val_loss: 0.3521 - val_accuracy: 0.9200\n","Epoch 16/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2518 - accuracy: 0.9355 - val_loss: 0.3505 - val_accuracy: 0.9200\n","Epoch 17/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2644 - accuracy: 0.9350 - val_loss: 0.3491 - val_accuracy: 0.9200\n","Epoch 18/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2509 - accuracy: 0.9370 - val_loss: 0.3486 - val_accuracy: 0.9200\n","Epoch 19/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2472 - accuracy: 0.9460 - val_loss: 0.3459 - val_accuracy: 0.9200\n","Epoch 20/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2395 - accuracy: 0.9475 - val_loss: 0.3454 - val_accuracy: 0.9200\n","Epoch 21/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2499 - accuracy: 0.9425 - val_loss: 0.3450 - val_accuracy: 0.9200\n","Epoch 22/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2497 - accuracy: 0.9420 - val_loss: 0.3431 - val_accuracy: 0.9200\n","Epoch 23/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2312 - accuracy: 0.9510 - val_loss: 0.3428 - val_accuracy: 0.9250\n","Epoch 24/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2446 - accuracy: 0.9450 - val_loss: 0.3407 - val_accuracy: 0.9250\n","Epoch 25/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2397 - accuracy: 0.9415 - val_loss: 0.3401 - val_accuracy: 0.9250\n","Epoch 26/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2310 - accuracy: 0.9475 - val_loss: 0.3390 - val_accuracy: 0.9250\n","Epoch 27/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2327 - accuracy: 0.9445 - val_loss: 0.3383 - val_accuracy: 0.9250\n","Epoch 28/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2321 - accuracy: 0.9475 - val_loss: 0.3370 - val_accuracy: 0.9250\n","Epoch 29/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2260 - accuracy: 0.9490 - val_loss: 0.3356 - val_accuracy: 0.9250\n","Epoch 30/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2262 - accuracy: 0.9530 - val_loss: 0.3356 - val_accuracy: 0.9250\n","Epoch 31/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2169 - accuracy: 0.9500 - val_loss: 0.3342 - val_accuracy: 0.9300\n","Epoch 32/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2199 - accuracy: 0.9480 - val_loss: 0.3328 - val_accuracy: 0.9300\n","Epoch 33/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2189 - accuracy: 0.9545 - val_loss: 0.3315 - val_accuracy: 0.9250\n","Epoch 34/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2245 - accuracy: 0.9490 - val_loss: 0.3298 - val_accuracy: 0.9300\n","Epoch 35/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2215 - accuracy: 0.9460 - val_loss: 0.3284 - val_accuracy: 0.9300\n","Epoch 36/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2194 - accuracy: 0.9495 - val_loss: 0.3278 - val_accuracy: 0.9300\n","Epoch 37/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2265 - accuracy: 0.9465 - val_loss: 0.3268 - val_accuracy: 0.9300\n","Epoch 38/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2211 - accuracy: 0.9515 - val_loss: 0.3267 - val_accuracy: 0.9300\n","Epoch 39/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2133 - accuracy: 0.9505 - val_loss: 0.3269 - val_accuracy: 0.9300\n","Epoch 40/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1974 - accuracy: 0.9580 - val_loss: 0.3260 - val_accuracy: 0.9300\n","Epoch 41/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2045 - accuracy: 0.9505 - val_loss: 0.3241 - val_accuracy: 0.9300\n","Epoch 42/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1988 - accuracy: 0.9565 - val_loss: 0.3241 - val_accuracy: 0.9300\n","Epoch 43/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1941 - accuracy: 0.9590 - val_loss: 0.3236 - val_accuracy: 0.9300\n","Epoch 44/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.2025 - accuracy: 0.9580 - val_loss: 0.3220 - val_accuracy: 0.9300\n","Epoch 45/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1929 - accuracy: 0.9600 - val_loss: 0.3217 - val_accuracy: 0.9300\n","Epoch 46/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.1912 - accuracy: 0.9620 - val_loss: 0.3209 - val_accuracy: 0.9300\n","Epoch 47/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.2022 - accuracy: 0.9550 - val_loss: 0.3197 - val_accuracy: 0.9300\n","Epoch 48/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.1971 - accuracy: 0.9585 - val_loss: 0.3198 - val_accuracy: 0.9300\n","Epoch 49/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1937 - accuracy: 0.9585 - val_loss: 0.3183 - val_accuracy: 0.9300\n","Epoch 50/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1988 - accuracy: 0.9590 - val_loss: 0.3181 - val_accuracy: 0.9300\n","Epoch 51/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1954 - accuracy: 0.9560 - val_loss: 0.3178 - val_accuracy: 0.9300\n","Epoch 52/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1972 - accuracy: 0.9580 - val_loss: 0.3170 - val_accuracy: 0.9300\n","Epoch 53/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1868 - accuracy: 0.9575 - val_loss: 0.3149 - val_accuracy: 0.9300\n","Epoch 54/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1871 - accuracy: 0.9575 - val_loss: 0.3147 - val_accuracy: 0.9300\n","Epoch 55/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.1842 - accuracy: 0.9615 - val_loss: 0.3143 - val_accuracy: 0.9300\n","Epoch 56/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.1837 - accuracy: 0.9615 - val_loss: 0.3140 - val_accuracy: 0.9300\n","Epoch 57/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1855 - accuracy: 0.9600 - val_loss: 0.3138 - val_accuracy: 0.9300\n","Epoch 58/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1696 - accuracy: 0.9665 - val_loss: 0.3116 - val_accuracy: 0.9300\n","Epoch 59/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1837 - accuracy: 0.9615 - val_loss: 0.3105 - val_accuracy: 0.9300\n","Epoch 60/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1757 - accuracy: 0.9640 - val_loss: 0.3090 - val_accuracy: 0.9350\n","Epoch 61/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1688 - accuracy: 0.9635 - val_loss: 0.3081 - val_accuracy: 0.9350\n","Epoch 62/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1823 - accuracy: 0.9635 - val_loss: 0.3083 - val_accuracy: 0.9350\n","Epoch 63/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.1708 - accuracy: 0.9605 - val_loss: 0.3079 - val_accuracy: 0.9350\n","Epoch 64/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1726 - accuracy: 0.9650 - val_loss: 0.3084 - val_accuracy: 0.9300\n","Epoch 65/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1792 - accuracy: 0.9610 - val_loss: 0.3067 - val_accuracy: 0.9350\n","Epoch 66/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.1643 - accuracy: 0.9685 - val_loss: 0.3063 - val_accuracy: 0.9350\n","Epoch 67/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1739 - accuracy: 0.9655 - val_loss: 0.3064 - val_accuracy: 0.9350\n","Epoch 68/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.1727 - accuracy: 0.9610 - val_loss: 0.3052 - val_accuracy: 0.9350\n","Epoch 69/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1712 - accuracy: 0.9615 - val_loss: 0.3043 - val_accuracy: 0.9350\n","Epoch 70/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1705 - accuracy: 0.9630 - val_loss: 0.3040 - val_accuracy: 0.9350\n","Epoch 71/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.1604 - accuracy: 0.9660 - val_loss: 0.3035 - val_accuracy: 0.9350\n","Epoch 72/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1497 - accuracy: 0.9735 - val_loss: 0.3031 - val_accuracy: 0.9350\n","Epoch 73/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1570 - accuracy: 0.9660 - val_loss: 0.3034 - val_accuracy: 0.9350\n","Epoch 74/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1637 - accuracy: 0.9665 - val_loss: 0.3027 - val_accuracy: 0.9350\n","Epoch 75/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1642 - accuracy: 0.9715 - val_loss: 0.3032 - val_accuracy: 0.9350\n","Epoch 76/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1619 - accuracy: 0.9660 - val_loss: 0.3016 - val_accuracy: 0.9350\n","Epoch 77/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1636 - accuracy: 0.9665 - val_loss: 0.3010 - val_accuracy: 0.9350\n","Epoch 78/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.1583 - accuracy: 0.9660 - val_loss: 0.3007 - val_accuracy: 0.9350\n","Epoch 79/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.1519 - accuracy: 0.9680 - val_loss: 0.3001 - val_accuracy: 0.9350\n","Epoch 80/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1487 - accuracy: 0.9710 - val_loss: 0.2999 - val_accuracy: 0.9350\n","Epoch 81/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.1518 - accuracy: 0.9745 - val_loss: 0.2990 - val_accuracy: 0.9350\n","Epoch 82/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1533 - accuracy: 0.9690 - val_loss: 0.2982 - val_accuracy: 0.9350\n","Epoch 83/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.1675 - accuracy: 0.9640 - val_loss: 0.2984 - val_accuracy: 0.9350\n","Epoch 84/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1548 - accuracy: 0.9685 - val_loss: 0.2978 - val_accuracy: 0.9350\n","Epoch 85/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1427 - accuracy: 0.9750 - val_loss: 0.2968 - val_accuracy: 0.9350\n","Epoch 86/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1432 - accuracy: 0.9710 - val_loss: 0.2964 - val_accuracy: 0.9350\n","Epoch 87/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1423 - accuracy: 0.9715 - val_loss: 0.2956 - val_accuracy: 0.9350\n","Epoch 88/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1445 - accuracy: 0.9775 - val_loss: 0.2955 - val_accuracy: 0.9350\n","Epoch 89/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1599 - accuracy: 0.9670 - val_loss: 0.2951 - val_accuracy: 0.9350\n","Epoch 90/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1353 - accuracy: 0.9755 - val_loss: 0.2943 - val_accuracy: 0.9350\n","Epoch 91/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1485 - accuracy: 0.9735 - val_loss: 0.2938 - val_accuracy: 0.9350\n","Epoch 92/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1434 - accuracy: 0.9725 - val_loss: 0.2928 - val_accuracy: 0.9350\n","Epoch 93/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.1387 - accuracy: 0.9735 - val_loss: 0.2930 - val_accuracy: 0.9350\n","Epoch 94/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.1419 - accuracy: 0.9745 - val_loss: 0.2927 - val_accuracy: 0.9350\n","Epoch 95/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1366 - accuracy: 0.9715 - val_loss: 0.2928 - val_accuracy: 0.9350\n","Epoch 96/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1352 - accuracy: 0.9795 - val_loss: 0.2920 - val_accuracy: 0.9350\n","Epoch 97/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.1294 - accuracy: 0.9800 - val_loss: 0.2922 - val_accuracy: 0.9350\n","Epoch 98/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.1354 - accuracy: 0.9750 - val_loss: 0.2921 - val_accuracy: 0.9350\n","Epoch 99/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.1334 - accuracy: 0.9725 - val_loss: 0.2916 - val_accuracy: 0.9350\n","Epoch 100/100\n","72/72 [==============================] - 0s 5ms/step - loss: 0.1361 - accuracy: 0.9780 - val_loss: 0.2900 - val_accuracy: 0.9350\n","Final model Test loss: 0.30092567205429077\n","Final model Test accuracy: 0.9097999930381775\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pykG_r-aEpSJ"},"source":["새로운 모델 만들어보기"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nPlW10ieEo0d","executionInfo":{"status":"ok","timestamp":1619188935345,"user_tz":-540,"elapsed":220553,"user":{"displayName":"김태영","photoUrl":"","userId":"02983489978232498818"}},"outputId":"027560ea-f4bb-4aaf-87f8-31aeceffb717"},"source":["new_model = Sequential()\n","### START CODE HERE ###\n","new_model.add(Flatten(input_shape=(28,28)))\n","new_model.add(Dense(784))\n","new_model.add(BatchNormalization())\n","new_model.add(Activation('relu'))\n","new_model.add(Dropout(0.3))\n","new_model.add(Dense(1024))\n","new_model.add(BatchNormalization())\n","new_model.add(Activation('relu'))\n","new_model.add(Dense(784))\n","new_model.add(BatchNormalization())\n","new_model.add(Activation('relu'))\n","new_model.add(Dense(1024))\n","new_model.add(BatchNormalization())\n","new_model.add(Activation('relu'))\n","new_model.add(Dropout(0.3))\n","new_model.add(Flatten(input_shape=(1024,)))\n","new_model.add(Dense(10,activation='softmax'))\n","### END CODE HERE ###\n","new_model.summary()"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","flatten_8 (Flatten)          (None, 784)               0         \n","_________________________________________________________________\n","dense_16 (Dense)             (None, 784)               615440    \n","_________________________________________________________________\n","batch_normalization_6 (Batch (None, 784)               3136      \n","_________________________________________________________________\n","activation_6 (Activation)    (None, 784)               0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 784)               0         \n","_________________________________________________________________\n","dense_17 (Dense)             (None, 1024)              803840    \n","_________________________________________________________________\n","batch_normalization_7 (Batch (None, 1024)              4096      \n","_________________________________________________________________\n","activation_7 (Activation)    (None, 1024)              0         \n","_________________________________________________________________\n","dense_18 (Dense)             (None, 784)               803600    \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 784)               3136      \n","_________________________________________________________________\n","activation_8 (Activation)    (None, 784)               0         \n","_________________________________________________________________\n","dense_19 (Dense)             (None, 1024)              803840    \n","_________________________________________________________________\n","batch_normalization_9 (Batch (None, 1024)              4096      \n","_________________________________________________________________\n","activation_9 (Activation)    (None, 1024)              0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 1024)              0         \n","_________________________________________________________________\n","flatten_9 (Flatten)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_20 (Dense)             (None, 10)                10250     \n","=================================================================\n","Total params: 3,051,434\n","Trainable params: 3,044,202\n","Non-trainable params: 7,232\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EjUKWCoaKdnq","executionInfo":{"status":"ok","timestamp":1619189114686,"user_tz":-540,"elapsed":48175,"user":{"displayName":"김태영","photoUrl":"","userId":"02983489978232498818"}},"outputId":"02449db3-d0a8-4e98-f24e-aee20c5534a7"},"source":["new_model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=keras.optimizers.Adadelta(),\n","              metrics=['accuracy'])\n","\n","new_model_history=new_model.fit(large_x_train_agg, large_y_train_agg,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          verbose=1,\n","          validation_data=(x_validation, y_validation))\n","\n","score = new_model.evaluate(x_test, y_test, verbose=0)\n","print('New model Test loss:', score[0])\n","print('New model Test accuracy:', score[1])"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","72/72 [==============================] - 2s 10ms/step - loss: 2.8114 - accuracy: 0.0986 - val_loss: 2.2928 - val_accuracy: 0.1850\n","Epoch 2/100\n","72/72 [==============================] - 0s 6ms/step - loss: 2.7580 - accuracy: 0.1116 - val_loss: 2.2648 - val_accuracy: 0.1900\n","Epoch 3/100\n","72/72 [==============================] - 0s 6ms/step - loss: 2.6254 - accuracy: 0.1322 - val_loss: 2.2123 - val_accuracy: 0.2300\n","Epoch 4/100\n","72/72 [==============================] - 0s 6ms/step - loss: 2.5180 - accuracy: 0.1436 - val_loss: 2.1427 - val_accuracy: 0.2650\n","Epoch 5/100\n","72/72 [==============================] - 0s 6ms/step - loss: 2.5305 - accuracy: 0.1589 - val_loss: 2.0678 - val_accuracy: 0.3000\n","Epoch 6/100\n","72/72 [==============================] - 0s 6ms/step - loss: 2.4423 - accuracy: 0.1712 - val_loss: 2.0014 - val_accuracy: 0.3250\n","Epoch 7/100\n","72/72 [==============================] - 0s 6ms/step - loss: 2.3483 - accuracy: 0.1694 - val_loss: 1.9350 - val_accuracy: 0.3600\n","Epoch 8/100\n","72/72 [==============================] - 0s 6ms/step - loss: 2.2780 - accuracy: 0.2068 - val_loss: 1.8742 - val_accuracy: 0.3850\n","Epoch 9/100\n","72/72 [==============================] - 0s 6ms/step - loss: 2.2535 - accuracy: 0.2418 - val_loss: 1.8149 - val_accuracy: 0.4150\n","Epoch 10/100\n","72/72 [==============================] - 0s 6ms/step - loss: 2.1897 - accuracy: 0.2409 - val_loss: 1.7623 - val_accuracy: 0.4400\n","Epoch 11/100\n","72/72 [==============================] - 0s 6ms/step - loss: 2.1198 - accuracy: 0.2784 - val_loss: 1.7126 - val_accuracy: 0.4750\n","Epoch 12/100\n","72/72 [==============================] - 0s 6ms/step - loss: 2.0965 - accuracy: 0.2637 - val_loss: 1.6618 - val_accuracy: 0.5000\n","Epoch 13/100\n","72/72 [==============================] - 0s 6ms/step - loss: 2.0264 - accuracy: 0.3003 - val_loss: 1.6167 - val_accuracy: 0.5400\n","Epoch 14/100\n","72/72 [==============================] - 0s 6ms/step - loss: 2.0811 - accuracy: 0.2852 - val_loss: 1.5681 - val_accuracy: 0.5800\n","Epoch 15/100\n","72/72 [==============================] - 0s 6ms/step - loss: 2.0050 - accuracy: 0.3047 - val_loss: 1.5268 - val_accuracy: 0.5800\n","Epoch 16/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.9085 - accuracy: 0.3553 - val_loss: 1.4859 - val_accuracy: 0.6100\n","Epoch 17/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.8587 - accuracy: 0.3631 - val_loss: 1.4454 - val_accuracy: 0.6250\n","Epoch 18/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.8931 - accuracy: 0.3574 - val_loss: 1.4079 - val_accuracy: 0.6350\n","Epoch 19/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.7610 - accuracy: 0.3942 - val_loss: 1.3762 - val_accuracy: 0.6600\n","Epoch 20/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.7334 - accuracy: 0.4194 - val_loss: 1.3410 - val_accuracy: 0.6650\n","Epoch 21/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.6962 - accuracy: 0.4396 - val_loss: 1.3079 - val_accuracy: 0.6750\n","Epoch 22/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.6559 - accuracy: 0.4426 - val_loss: 1.2773 - val_accuracy: 0.6850\n","Epoch 23/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.6712 - accuracy: 0.4367 - val_loss: 1.2476 - val_accuracy: 0.6900\n","Epoch 24/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.6333 - accuracy: 0.4504 - val_loss: 1.2212 - val_accuracy: 0.7000\n","Epoch 25/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.5876 - accuracy: 0.4711 - val_loss: 1.1931 - val_accuracy: 0.7050\n","Epoch 26/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.5727 - accuracy: 0.4787 - val_loss: 1.1621 - val_accuracy: 0.7050\n","Epoch 27/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.5571 - accuracy: 0.4940 - val_loss: 1.1385 - val_accuracy: 0.7050\n","Epoch 28/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.5166 - accuracy: 0.5177 - val_loss: 1.1170 - val_accuracy: 0.7050\n","Epoch 29/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.4892 - accuracy: 0.5163 - val_loss: 1.0956 - val_accuracy: 0.7100\n","Epoch 30/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.4672 - accuracy: 0.5249 - val_loss: 1.0749 - val_accuracy: 0.7200\n","Epoch 31/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.4495 - accuracy: 0.5122 - val_loss: 1.0545 - val_accuracy: 0.7200\n","Epoch 32/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.4550 - accuracy: 0.5264 - val_loss: 1.0353 - val_accuracy: 0.7250\n","Epoch 33/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.3765 - accuracy: 0.5625 - val_loss: 1.0179 - val_accuracy: 0.7400\n","Epoch 34/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.4239 - accuracy: 0.5487 - val_loss: 0.9998 - val_accuracy: 0.7400\n","Epoch 35/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.3460 - accuracy: 0.5585 - val_loss: 0.9841 - val_accuracy: 0.7400\n","Epoch 36/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.3355 - accuracy: 0.5688 - val_loss: 0.9672 - val_accuracy: 0.7550\n","Epoch 37/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.3657 - accuracy: 0.5528 - val_loss: 0.9510 - val_accuracy: 0.7550\n","Epoch 38/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.2455 - accuracy: 0.6112 - val_loss: 0.9341 - val_accuracy: 0.7750\n","Epoch 39/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.1967 - accuracy: 0.5989 - val_loss: 0.9197 - val_accuracy: 0.7750\n","Epoch 40/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.2202 - accuracy: 0.6153 - val_loss: 0.9042 - val_accuracy: 0.7700\n","Epoch 41/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.2453 - accuracy: 0.5969 - val_loss: 0.8911 - val_accuracy: 0.7700\n","Epoch 42/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.1923 - accuracy: 0.6065 - val_loss: 0.8784 - val_accuracy: 0.7750\n","Epoch 43/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.2310 - accuracy: 0.6068 - val_loss: 0.8637 - val_accuracy: 0.7700\n","Epoch 44/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.1461 - accuracy: 0.6417 - val_loss: 0.8528 - val_accuracy: 0.7700\n","Epoch 45/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.1732 - accuracy: 0.6450 - val_loss: 0.8401 - val_accuracy: 0.7750\n","Epoch 46/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.1155 - accuracy: 0.6557 - val_loss: 0.8293 - val_accuracy: 0.7800\n","Epoch 47/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.0887 - accuracy: 0.6581 - val_loss: 0.8177 - val_accuracy: 0.7800\n","Epoch 48/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.1291 - accuracy: 0.6500 - val_loss: 0.8076 - val_accuracy: 0.7850\n","Epoch 49/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.1157 - accuracy: 0.6481 - val_loss: 0.7996 - val_accuracy: 0.7850\n","Epoch 50/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.0512 - accuracy: 0.6666 - val_loss: 0.7881 - val_accuracy: 0.7800\n","Epoch 51/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.0608 - accuracy: 0.6654 - val_loss: 0.7797 - val_accuracy: 0.7850\n","Epoch 52/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.0114 - accuracy: 0.6882 - val_loss: 0.7689 - val_accuracy: 0.7850\n","Epoch 53/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.0424 - accuracy: 0.6838 - val_loss: 0.7580 - val_accuracy: 0.7850\n","Epoch 54/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.0169 - accuracy: 0.6900 - val_loss: 0.7498 - val_accuracy: 0.7850\n","Epoch 55/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.0033 - accuracy: 0.6797 - val_loss: 0.7414 - val_accuracy: 0.7850\n","Epoch 56/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.0357 - accuracy: 0.6798 - val_loss: 0.7337 - val_accuracy: 0.7900\n","Epoch 57/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.0356 - accuracy: 0.6692 - val_loss: 0.7263 - val_accuracy: 0.7900\n","Epoch 58/100\n","72/72 [==============================] - 0s 6ms/step - loss: 1.0488 - accuracy: 0.6775 - val_loss: 0.7191 - val_accuracy: 0.7900\n","Epoch 59/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.9519 - accuracy: 0.7077 - val_loss: 0.7134 - val_accuracy: 0.7950\n","Epoch 60/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.9579 - accuracy: 0.7054 - val_loss: 0.7023 - val_accuracy: 0.7950\n","Epoch 61/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.9576 - accuracy: 0.7069 - val_loss: 0.6946 - val_accuracy: 0.7950\n","Epoch 62/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.9152 - accuracy: 0.7073 - val_loss: 0.6875 - val_accuracy: 0.8000\n","Epoch 63/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.9475 - accuracy: 0.7036 - val_loss: 0.6809 - val_accuracy: 0.8050\n","Epoch 64/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.9328 - accuracy: 0.7062 - val_loss: 0.6735 - val_accuracy: 0.8050\n","Epoch 65/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.9372 - accuracy: 0.7060 - val_loss: 0.6697 - val_accuracy: 0.8050\n","Epoch 66/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.8949 - accuracy: 0.7200 - val_loss: 0.6634 - val_accuracy: 0.8050\n","Epoch 67/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.8826 - accuracy: 0.7197 - val_loss: 0.6568 - val_accuracy: 0.8050\n","Epoch 68/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.8819 - accuracy: 0.7330 - val_loss: 0.6516 - val_accuracy: 0.8050\n","Epoch 69/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.9070 - accuracy: 0.7184 - val_loss: 0.6452 - val_accuracy: 0.8150\n","Epoch 70/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.9042 - accuracy: 0.7230 - val_loss: 0.6404 - val_accuracy: 0.8200\n","Epoch 71/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.8931 - accuracy: 0.7119 - val_loss: 0.6341 - val_accuracy: 0.8200\n","Epoch 72/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.8283 - accuracy: 0.7581 - val_loss: 0.6294 - val_accuracy: 0.8200\n","Epoch 73/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.8386 - accuracy: 0.7427 - val_loss: 0.6255 - val_accuracy: 0.8200\n","Epoch 74/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.8917 - accuracy: 0.7303 - val_loss: 0.6190 - val_accuracy: 0.8200\n","Epoch 75/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.8577 - accuracy: 0.7347 - val_loss: 0.6124 - val_accuracy: 0.8200\n","Epoch 76/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.8327 - accuracy: 0.7339 - val_loss: 0.6067 - val_accuracy: 0.8250\n","Epoch 77/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.8265 - accuracy: 0.7532 - val_loss: 0.6028 - val_accuracy: 0.8200\n","Epoch 78/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.7818 - accuracy: 0.7658 - val_loss: 0.5988 - val_accuracy: 0.8250\n","Epoch 79/100\n","72/72 [==============================] - 0s 7ms/step - loss: 0.7523 - accuracy: 0.7696 - val_loss: 0.5951 - val_accuracy: 0.8250\n","Epoch 80/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.7982 - accuracy: 0.7409 - val_loss: 0.5895 - val_accuracy: 0.8350\n","Epoch 81/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.7866 - accuracy: 0.7565 - val_loss: 0.5845 - val_accuracy: 0.8350\n","Epoch 82/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.8015 - accuracy: 0.7567 - val_loss: 0.5813 - val_accuracy: 0.8350\n","Epoch 83/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.7635 - accuracy: 0.7544 - val_loss: 0.5774 - val_accuracy: 0.8350\n","Epoch 84/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.7989 - accuracy: 0.7557 - val_loss: 0.5718 - val_accuracy: 0.8400\n","Epoch 85/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.7564 - accuracy: 0.7599 - val_loss: 0.5680 - val_accuracy: 0.8400\n","Epoch 86/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.7746 - accuracy: 0.7667 - val_loss: 0.5648 - val_accuracy: 0.8400\n","Epoch 87/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.7457 - accuracy: 0.7573 - val_loss: 0.5616 - val_accuracy: 0.8400\n","Epoch 88/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.7223 - accuracy: 0.7803 - val_loss: 0.5586 - val_accuracy: 0.8400\n","Epoch 89/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.7460 - accuracy: 0.7622 - val_loss: 0.5541 - val_accuracy: 0.8450\n","Epoch 90/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.7624 - accuracy: 0.7741 - val_loss: 0.5505 - val_accuracy: 0.8450\n","Epoch 91/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.7206 - accuracy: 0.7804 - val_loss: 0.5484 - val_accuracy: 0.8500\n","Epoch 92/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.7037 - accuracy: 0.7885 - val_loss: 0.5427 - val_accuracy: 0.8500\n","Epoch 93/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.7037 - accuracy: 0.7899 - val_loss: 0.5387 - val_accuracy: 0.8550\n","Epoch 94/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.7404 - accuracy: 0.7757 - val_loss: 0.5360 - val_accuracy: 0.8600\n","Epoch 95/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.6767 - accuracy: 0.7956 - val_loss: 0.5324 - val_accuracy: 0.8650\n","Epoch 96/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.7003 - accuracy: 0.7761 - val_loss: 0.5291 - val_accuracy: 0.8650\n","Epoch 97/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.6814 - accuracy: 0.8003 - val_loss: 0.5271 - val_accuracy: 0.8650\n","Epoch 98/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.7041 - accuracy: 0.7803 - val_loss: 0.5231 - val_accuracy: 0.8650\n","Epoch 99/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.7007 - accuracy: 0.7893 - val_loss: 0.5206 - val_accuracy: 0.8650\n","Epoch 100/100\n","72/72 [==============================] - 0s 6ms/step - loss: 0.6855 - accuracy: 0.7918 - val_loss: 0.5179 - val_accuracy: 0.8700\n","Final model Test loss: 0.544910728931427\n","Final model Test accuracy: 0.8468000292778015\n"],"name":"stdout"}]}]}